{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GTmycology/dreambooth-colab/blob/main/Lora_Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmCPmqFL6hCQ"
      },
      "source": [
        "# ⭐ Lora Trainer by Hollowstrawberry\n",
        "\n",
        "This is based on the work of [Kohya-ss](https://github.com/kohya-ss/sd-scripts) and [Linaqruf](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb). Thank you!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ8clWTZEu-g"
      },
      "source": [
        "### ⭕ Disclaimer\n",
        "The purpose of this document is to research bleeding-edge technologies in the field of machine learning.  \n",
        "Please read and follow the [Google Colab guidelines](https://research.google.com/colaboratory/faq.html) and its [Terms of Service](https://research.google.com/colaboratory/tos_v3.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPQlB4djNm3C"
      },
      "source": [
        "| |GitHub|🇬🇧 English|🇪🇸 Spanish|\n",
        "|:--|:-:|:-:|:-:|\n",
        "| 🏠 **Homepage** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab) | | |\n",
        "| 📊 **Dataset Maker** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Dataset_Maker.ipynb) |\n",
        "| ⭐ **Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) |\n",
        "| 🌟 **XL Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) |  |\n",
        "| 🌟 **Legacy XL Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL_Legacy.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL_Legacy.ipynb) |  |"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate.utils import write_basic_config\n",
        "import os\n",
        "\n",
        "repo_dir = \"/content/kohya-trainer\"\n",
        "accelerate_config_file = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "\n",
        "os.makedirs(os.path.dirname(accelerate_config_file), exist_ok=True)\n",
        "write_basic_config(save_location=accelerate_config_file)\n",
        "\n",
        "print(f\"✅ Accelerate config created at: {accelerate_config_file}\")\n"
      ],
      "metadata": {
        "id": "FhRWlhanhlTp",
        "outputId": "81248436-066b-45f3-a8c8-3b72316c5b86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accelerate config created at: /content/kohya-trainer/accelerate_config/config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "OglZzI_ujZq-",
        "outputId": "dcd95d2b-7eef-406f-898d-090f1e1e14e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accelerate config already exists\n",
            "\n",
            "🚀 Starting Playful Origins v4.4 Angel Run\n",
            "\n",
            "✅ Dependencies already installed.\n",
            "\n",
            "💿 Checking dataset...\n",
            "📁 /content/drive/MyDrive/Loras/playful_origins_v4/dataset_v2/class1/PlayfulOrigins_00001\n",
            "📈 Found 30 images with 10 repeats, equaling 300 steps.\n",
            "📝 Captions found: 30\n",
            "✅ Using existing model: /content/drive/MyDrive/Loras/playful_origins_v4/sd-nsfw-v1-5-realism.ckpt\n",
            "📄 Configs saved to /content/drive/MyDrive/Loras/playful_origins_v4\n",
            "\n",
            "⭐ Starting trainer...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "import os, re, toml\n",
        "from time import time\n",
        "from IPython.display import Markdown, display\n",
        "from accelerate.utils import write_basic_config\n",
        "\n",
        "# --- Core setup ---\n",
        "COLAB = True\n",
        "XFORMERS = True\n",
        "SOURCE = \"https://github.com/uYouUs/sd-scripts\"\n",
        "COMMIT = None\n",
        "BETTER_EPOCH_NAMES = True\n",
        "LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# --- Project info ---\n",
        "project_name = \"playful_origins_v4_4\"\n",
        "model_url = \"/content/drive/MyDrive/Loras/playful_origins_v4/sd-nsfw-v1-5-realism.ckpt\"\n",
        "images_folder = \"/content/drive/MyDrive/Loras/playful_origins_v4/dataset_v2/class1/PlayfulOrigins_00001\"\n",
        "output_folder = \"/content/drive/MyDrive/Loras/playful_origins_v4/output_lora\"\n",
        "config_folder = \"/content/drive/MyDrive/Loras/playful_origins_v4\"\n",
        "log_folder = \"/content/drive/MyDrive/Loras/playful_origins_v4/_logs\"\n",
        "\n",
        "config_file = os.path.join(config_folder, \"training_config.toml\")\n",
        "dataset_config_file = os.path.join(config_folder, \"dataset_config.toml\")\n",
        "repo_dir = \"/content/kohya-trainer\"\n",
        "accelerate_config_file = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "\n",
        "# --- Create accelerate config if missing ---\n",
        "os.makedirs(os.path.dirname(accelerate_config_file), exist_ok=True)\n",
        "if not os.path.exists(accelerate_config_file):\n",
        "    write_basic_config(save_location=accelerate_config_file)\n",
        "    print(f\"✅ Accelerate config created at {accelerate_config_file}\")\n",
        "else:\n",
        "    print(f\"✅ Accelerate config already exists\")\n",
        "\n",
        "# --- Training parameters ---\n",
        "resolution = 768\n",
        "num_repeats = 10\n",
        "preferred_unit = \"Steps\"\n",
        "how_many = 2222\n",
        "max_train_epochs = how_many if preferred_unit == \"Epochs\" else None\n",
        "max_train_steps = how_many if preferred_unit == \"Steps\" else None\n",
        "train_batch_size = 2\n",
        "unet_lr = 5e-4\n",
        "text_encoder_lr = 1e-4\n",
        "lr_scheduler = \"cosine_with_restarts\"\n",
        "lr_scheduler_number = 3\n",
        "lr_scheduler_num_cycles = 3\n",
        "lr_warmup_ratio = 0.05\n",
        "min_snr_gamma_value = 5.0\n",
        "lora_type = \"LoRA\"\n",
        "network_dim = 32\n",
        "network_alpha = 16\n",
        "conv_dim = 8\n",
        "conv_alpha = 4\n",
        "\n",
        "# --- Dataset check ---\n",
        "def validate_dataset():\n",
        "    supported_types = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")\n",
        "    print(\"\\n💿 Checking dataset...\")\n",
        "    if not os.path.exists(images_folder):\n",
        "        print(f\"💥 Error: Dataset folder not found -> {images_folder}\")\n",
        "        return False\n",
        "    imgs = [f for f in os.listdir(images_folder) if f.lower().endswith(supported_types)]\n",
        "    txts = [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]\n",
        "    print(f\"📁 {images_folder}\")\n",
        "    print(f\"📈 Found {len(imgs)} images with {num_repeats} repeats, equaling {len(imgs)*num_repeats} steps.\")\n",
        "    print(f\"📝 Captions found: {len(txts)}\")\n",
        "    if len(imgs) == 0:\n",
        "        print(\"💥 Error: No images found.\")\n",
        "        return False\n",
        "    if len(txts) == 0:\n",
        "        print(\"⚠️ WARNING: 0 captions found — check dataset!\")\n",
        "    return True\n",
        "\n",
        "# --- Config creation ---\n",
        "def create_config():\n",
        "    dataset_config = {\n",
        "        \"general\": {\n",
        "            \"resolution\": resolution,\n",
        "            \"flip_aug\": False,\n",
        "            \"caption_extension\": \".txt\",\n",
        "            \"enable_bucket\": True,\n",
        "            \"bucket_reso_steps\": 64,\n",
        "            \"bucket_no_upscale\": False,\n",
        "        },\n",
        "        \"datasets\": [\n",
        "            {\n",
        "                \"subsets\": [\n",
        "                    {\n",
        "                        \"num_repeats\": num_repeats,\n",
        "                        \"image_dir\": images_folder,\n",
        "                        \"class_tokens\": None\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    train_config = {\n",
        "        \"additional_network_arguments\": {\n",
        "            \"unet_lr\": unet_lr,\n",
        "            \"text_encoder_lr\": text_encoder_lr,\n",
        "            \"network_dim\": network_dim,\n",
        "            \"network_alpha\": network_alpha,\n",
        "            \"network_module\": \"networks.lora\",\n",
        "        },\n",
        "        \"optimizer_arguments\": {\n",
        "            \"learning_rate\": unet_lr,\n",
        "            \"lr_scheduler\": lr_scheduler,\n",
        "            \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles,\n",
        "            \"lr_warmup_steps\": int(how_many * lr_warmup_ratio),\n",
        "            \"optimizer_type\": \"AdamW8bit\",\n",
        "        },\n",
        "        \"training_arguments\": {\n",
        "            \"max_train_steps\": max_train_steps,\n",
        "            \"train_batch_size\": train_batch_size,\n",
        "            \"min_snr_gamma\": min_snr_gamma_value,\n",
        "            \"mixed_precision\": \"fp16\",\n",
        "            \"save_every_n_epochs\": 1,\n",
        "            \"save_last_n_epochs\": 14,\n",
        "            \"output_dir\": output_folder,\n",
        "            \"logging_dir\": log_folder,\n",
        "            \"output_name\": project_name,\n",
        "        },\n",
        "        \"model_arguments\": {\n",
        "            \"pretrained_model_name_or_path\": model_url,\n",
        "            \"v2\": False,\n",
        "        },\n",
        "        \"saving_arguments\": {\n",
        "            \"save_model_as\": \"safetensors\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    os.makedirs(config_folder, exist_ok=True)\n",
        "    with open(config_file, \"w\") as f:\n",
        "        f.write(toml.dumps(train_config))\n",
        "    with open(dataset_config_file, \"w\") as f:\n",
        "        f.write(toml.dumps(dataset_config))\n",
        "\n",
        "    print(f\"📄 Configs saved to {config_folder}\")\n",
        "\n",
        "# --- Main ---\n",
        "def main():\n",
        "    print(\"\\n🚀 Starting Playful Origins v4.4 Angel Run\")\n",
        "    print(\"\\n✅ Dependencies already installed.\")\n",
        "    if not validate_dataset():\n",
        "        return\n",
        "    print(f\"✅ Using existing model: {model_url}\")\n",
        "    create_config()\n",
        "\n",
        "    print(\"\\n⭐ Starting trainer...\\n\")\n",
        "    os.chdir(repo_dir)\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "    os.system(f\"accelerate launch --config_file={accelerate_config_file} \"\n",
        "              f\"--num_cpu_threads_per_process=1 train_network_wrapper.py \"\n",
        "              f\"--dataset_config={dataset_config_file} --config_file={config_file}\")\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔧 Reduce memory load for T4\n",
        "import os\n",
        "\n",
        "# Make PyTorch use expandable memory segments (helps fragmentation)\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# These are the lighter settings for your rerun:\n",
        "train_batch_size = 1          # was 2\n",
        "resolution = 704              # was 768\n",
        "network_dim = 16              # was 32\n",
        "network_alpha = 8             # half of dim\n",
        "\n",
        "print(\"✅ Memory-safe config applied (batch=1, res=704, dim=16, alpha=8)\")\n"
      ],
      "metadata": {
        "id": "azF_r6K6kjJb",
        "outputId": "f9501e4e-b94d-4d62-e605-237aff07652e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Memory-safe config applied (batch=1, res=704, dim=16, alpha=8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚀 Clean Launch — Low VRAM Safe Mode for T4 (Playful Origins v4.4)\n",
        "import os, toml, time, re\n",
        "\n",
        "print(\"🔄 Forcing clean launch in low-VRAM mode...\")\n",
        "\n",
        "# --- 🔧 Memory environment tweaks\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,max_split_size_mb:256\"\n",
        "os.environ[\"TORCH_CUDA_ALLOC_CONF\"] = \"garbage_collection_threshold:0.8,max_split_size_mb:128\"\n",
        "\n",
        "# --- ✅ Safe training parameters\n",
        "train_batch_size = 1\n",
        "resolution = 640\n",
        "network_dim = 8\n",
        "network_alpha = 4\n",
        "print(f\"✅ Using resolution={resolution}, batch={train_batch_size}, dim={network_dim}, alpha={network_alpha}\")\n",
        "\n",
        "# --- 🗂️ Core paths\n",
        "project_root = \"/content/drive/MyDrive/Loras/playful_origins_v4\"\n",
        "dataset_path = f\"{project_root}/dataset_v2/class1/PlayfulOrigins_00001\"\n",
        "model_ckpt = f\"{project_root}/sd-nsfw-v1-5-realism.ckpt\"\n",
        "config_file = f\"{project_root}/training_config.toml\"\n",
        "dataset_config_file = f\"{project_root}/dataset_config.toml\"\n",
        "accelerate_config = \"/content/kohya-trainer/accelerate_config/config.yaml\"\n",
        "\n",
        "# --- 🔁 Overwrite dataset config with new resolution & batch size\n",
        "dataset_conf = {\n",
        "    \"general\": {\n",
        "        \"resolution\": resolution,\n",
        "        \"shuffle_caption\": False,\n",
        "        \"keep_tokens\": 0,\n",
        "        \"flip_aug\": False,\n",
        "        \"caption_extension\": \".txt\",\n",
        "        \"enable_bucket\": True,\n",
        "        \"bucket_reso_steps\": 64,\n",
        "        \"bucket_no_upscale\": False,\n",
        "        \"min_bucket_reso\": 256,\n",
        "        \"max_bucket_reso\": 1024,\n",
        "    },\n",
        "    \"datasets\": [\n",
        "        {\"subsets\": [\n",
        "            {\"num_repeats\": 10, \"image_dir\": dataset_path, \"class_tokens\": None}\n",
        "        ]}\n",
        "    ]\n",
        "}\n",
        "with open(dataset_config_file, \"w\") as f:\n",
        "    toml.dump(dataset_conf, f)\n",
        "print(f\"📄 Updated dataset config: {dataset_config_file}\")\n",
        "\n",
        "# --- 🔁 Overwrite training config to ensure dim/alpha/batch apply\n",
        "train_conf = {\n",
        "    \"additional_network_arguments\": {\n",
        "        \"unet_lr\": 5e-4,\n",
        "        \"text_encoder_lr\": 1e-4,\n",
        "        \"network_dim\": network_dim,\n",
        "        \"network_alpha\": network_alpha,\n",
        "        \"network_module\": \"networks.lora\",\n",
        "        \"network_train_unet_only\": False,\n",
        "    },\n",
        "    \"optimizer_arguments\": {\n",
        "        \"learning_rate\": 5e-4,\n",
        "        \"lr_scheduler\": \"cosine_with_restarts\",\n",
        "        \"lr_scheduler_num_cycles\": 3,\n",
        "        \"lr_warmup_steps\": 100,\n",
        "        \"optimizer_type\": \"AdamW8bit\",\n",
        "    },\n",
        "    \"training_arguments\": {\n",
        "        \"max_train_steps\": 2222,\n",
        "        \"train_batch_size\": train_batch_size,\n",
        "        \"save_every_n_epochs\": 1,\n",
        "        \"save_last_n_epochs\": 14,\n",
        "        \"clip_skip\": 2,\n",
        "        \"min_snr_gamma\": 5.0,\n",
        "        \"xformers\": True,\n",
        "        \"lowram\": True,\n",
        "        \"save_precision\": \"fp16\",\n",
        "        \"mixed_precision\": \"fp16\",\n",
        "        \"output_dir\": f\"{project_root}/output_lora\",\n",
        "        \"logging_dir\": f\"{project_root}/_logs\",\n",
        "        \"output_name\": \"playful_origins_v4_4\",\n",
        "        \"log_prefix\": \"playful_origins_v4_4\",\n",
        "    },\n",
        "    \"model_arguments\": {\"pretrained_model_name_or_path\": model_ckpt},\n",
        "    \"saving_arguments\": {\"save_model_as\": \"safetensors\"},\n",
        "}\n",
        "with open(config_file, \"w\") as f:\n",
        "    toml.dump(train_conf, f)\n",
        "print(f\"📄 Updated training config: {config_file}\")\n",
        "\n",
        "# --- 🌟 Launch trainer\n",
        "os.chdir(\"/content/kohya-trainer\")\n",
        "print(\"\\n⭐ Starting trainer...\\n\")\n",
        "!accelerate launch --config_file={accelerate_config} --num_cpu_threads_per_process=1 train_network_wrapper.py \\\n",
        "  --dataset_config={dataset_config_file} --config_file={config_file}\n"
      ],
      "metadata": {
        "id": "hxGJvyJQlZ3m",
        "outputId": "3e24107c-2d9a-49b1-c610-a3463c304aea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Forcing clean launch in low-VRAM mode...\n",
            "✅ Using resolution=640, batch=1, dim=8, alpha=4\n",
            "📄 Updated dataset config: /content/drive/MyDrive/Loras/playful_origins_v4/dataset_config.toml\n",
            "📄 Updated training config: /content/drive/MyDrive/Loras/playful_origins_v4/training_config.toml\n",
            "\n",
            "⭐ Starting trainer...\n",
            "\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761802054.515490   11838 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761802054.522912   11838 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761802054.539855   11838 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761802054.539887   11838 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761802054.539892   11838 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761802054.539896   11838 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.12/dist-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
            "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
            "/usr/local/lib/python3.12/dist-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
            "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n",
            "Loading settings from /content/drive/MyDrive/Loras/playful_origins_v4/training_config.toml...\n",
            "/content/drive/MyDrive/Loras/playful_origins_v4/training_config\n",
            "prepare tokenizer\n",
            "Loading dataset config from /content/drive/MyDrive/Loras/playful_origins_v4/dataset_config.toml\n",
            "prepare images.\n",
            "found directory /content/drive/MyDrive/Loras/playful_origins_v4/dataset_v2/class1/PlayfulOrigins_00001 contains 30 image files\n",
            "300 train images with repeating.\n",
            "0 reg images.\n",
            "no regularization images / 正則化画像が見つかりませんでした\n",
            "[Dataset 0]\n",
            "  batch_size: 1\n",
            "  resolution: (640, 640)\n",
            "  enable_bucket: True\n",
            "  network_multiplier: 1.0\n",
            "  min_bucket_reso: 256\n",
            "  max_bucket_reso: 1024\n",
            "  bucket_reso_steps: 64\n",
            "  bucket_no_upscale: False\n",
            "\n",
            "  [Subset 0 of Dataset 0]\n",
            "    image_dir: \"/content/drive/MyDrive/Loras/playful_origins_v4/dataset_v2/class1/PlayfulOrigins_00001\"\n",
            "    image_count: 30\n",
            "    num_repeats: 10\n",
            "    shuffle_caption: False\n",
            "    keep_tokens: 0\n",
            "    keep_tokens_separator: \n",
            "    caption_separator: ,\n",
            "    secondary_separator: None\n",
            "    enable_wildcard: False\n",
            "    caption_dropout_rate: 0.0\n",
            "    caption_dropout_every_n_epoches: 0\n",
            "    caption_tag_dropout_rate: 0.0\n",
            "    caption_prefix: None\n",
            "    caption_suffix: None\n",
            "    color_aug: False\n",
            "    flip_aug: False\n",
            "    face_crop_aug_range: None\n",
            "    random_crop: False\n",
            "    token_warmup_min: 1,\n",
            "    token_warmup_step: 0,\n",
            "    alpha_mask: False,\n",
            "    is_reg: False\n",
            "    class_tokens: None\n",
            "    caption_extension: .txt\n",
            "\n",
            "\n",
            "[Dataset 0]\n",
            "loading image sizes.\n",
            "100% 30/30 [00:00<00:00, 699.88it/s]\n",
            "make buckets\n",
            "number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n",
            "bucket 0: resolution (384, 960), count: 10\n",
            "bucket 1: resolution (448, 896), count: 10\n",
            "bucket 2: resolution (576, 704), count: 30\n",
            "bucket 3: resolution (640, 640), count: 200\n",
            "bucket 4: resolution (704, 576), count: 30\n",
            "bucket 5: resolution (768, 512), count: 10\n",
            "bucket 6: resolution (896, 448), count: 10\n",
            "mean ar error (without repeats): 0.05891921454946703\n",
            "preparing accelerator\n",
            "accelerator device: cuda\n",
            "loading model for process 0/1\n",
            "load StableDiffusion checkpoint: /content/drive/MyDrive/Loras/playful_origins_v4/sd-nsfw-v1-5-realism.ckpt\n",
            "/content/kohya-trainer/library/model_util.py:977: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(ckpt_path, map_location=device)\n",
            "UNet2DConditionModel: 64, 8, 768, False, False\n",
            "loading u-net: <All keys matched successfully>\n",
            "loading vae: <All keys matched successfully>\n",
            "loading text encoder: <All keys matched successfully>\n",
            "Enable xformers for U-Net\n",
            "import network module: networks.lora\n",
            "create LoRA network. base dim (rank): 8, alpha: 4\n",
            "neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
            "create LoRA for Text Encoder:\n",
            "create LoRA for Text Encoder: 72 modules.\n",
            "create LoRA for U-Net: 192 modules.\n",
            "enable LoRA for text encoder: 72 modules\n",
            "enable LoRA for U-Net: 192 modules\n",
            "prepare optimizer, data loader etc.\n",
            "use 8-bit AdamW optimizer | {}\n",
            "running training / 学習開始\n",
            "  num train images * repeats / 学習画像の数×繰り返し回数: 300\n",
            "  num reg images / 正則化画像の数: 0\n",
            "  num batches per epoch / 1epochのバッチ数: 300\n",
            "  num epochs / epoch数: 8\n",
            "  batch size per device / バッチサイズ: 1\n",
            "  gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
            "  total optimization steps / 学習ステップ数: 2222\n",
            "steps:   0% 0/2222 [00:00<?, ?it/s]\n",
            "epoch 1/8\n",
            "epoch is incremented. current_epoch: 0, epoch: 1\n",
            "epoch is incremented. current_epoch: 0, epoch: 1\n",
            "epoch is incremented. current_epoch: 0, epoch: 1\n",
            "epoch is incremented. current_epoch: 0, epoch: 1\n",
            "epoch is incremented. current_epoch: 0, epoch: 1\n",
            "epoch is incremented. current_epoch: 0, epoch: 1\n",
            "epoch is incremented. current_epoch: 0, epoch: 1\n",
            "epoch is incremented. current_epoch: 0, epoch: 1\n",
            "steps:  14% 300/2222 [05:33<35:38,  1.11s/it, avr_loss=0.0727]\n",
            "saving checkpoint: /content/drive/MyDrive/Loras/playful_origins_v4/output_lora/playful_origins_v4_4-01.safetensors\n",
            "\n",
            "epoch 2/8\n",
            "epoch is incremented. current_epoch: 0, epoch: 2\n",
            "epoch is incremented. current_epoch: 0, epoch: 2\n",
            "epoch is incremented. current_epoch: 0, epoch: 2\n",
            "epoch is incremented. current_epoch: 0, epoch: 2\n",
            "epoch is incremented. current_epoch: 0, epoch: 2\n",
            "epoch is incremented. current_epoch: 0, epoch: 2\n",
            "epoch is incremented. current_epoch: 0, epoch: 2\n",
            "epoch is incremented. current_epoch: 0, epoch: 2\n",
            "steps:  27% 600/2222 [11:08<30:06,  1.11s/it, avr_loss=0.0684]\n",
            "saving checkpoint: /content/drive/MyDrive/Loras/playful_origins_v4/output_lora/playful_origins_v4_4-02.safetensors\n",
            "\n",
            "epoch 3/8\n",
            "epoch is incremented. current_epoch: 0, epoch: 3\n",
            "epoch is incremented. current_epoch: 0, epoch: 3\n",
            "epoch is incremented. current_epoch: 0, epoch: 3\n",
            "epoch is incremented. current_epoch: 0, epoch: 3\n",
            "epoch is incremented. current_epoch: 0, epoch: 3\n",
            "epoch is incremented. current_epoch: 0, epoch: 3\n",
            "epoch is incremented. current_epoch: 0, epoch: 3\n",
            "epoch is incremented. current_epoch: 0, epoch: 3\n",
            "steps:  41% 900/2222 [16:42<24:32,  1.11s/it, avr_loss=0.0637]\n",
            "saving checkpoint: /content/drive/MyDrive/Loras/playful_origins_v4/output_lora/playful_origins_v4_4-03.safetensors\n",
            "\n",
            "epoch 4/8\n",
            "epoch is incremented. current_epoch: 0, epoch: 4\n",
            "epoch is incremented. current_epoch: 0, epoch: 4\n",
            "epoch is incremented. current_epoch: 0, epoch: 4\n",
            "epoch is incremented. current_epoch: 0, epoch: 4\n",
            "epoch is incremented. current_epoch: 0, epoch: 4\n",
            "epoch is incremented. current_epoch: 0, epoch: 4\n",
            "epoch is incremented. current_epoch: 0, epoch: 4\n",
            "epoch is incremented. current_epoch: 0, epoch: 4\n",
            "steps:  54% 1200/2222 [22:16<18:58,  1.11s/it, avr_loss=0.0689]\n",
            "saving checkpoint: /content/drive/MyDrive/Loras/playful_origins_v4/output_lora/playful_origins_v4_4-04.safetensors\n",
            "\n",
            "epoch 5/8\n",
            "epoch is incremented. current_epoch: 0, epoch: 5\n",
            "epoch is incremented. current_epoch: 0, epoch: 5\n",
            "epoch is incremented. current_epoch: 0, epoch: 5\n",
            "epoch is incremented. current_epoch: 0, epoch: 5\n",
            "epoch is incremented. current_epoch: 0, epoch: 5\n",
            "epoch is incremented. current_epoch: 0, epoch: 5\n",
            "epoch is incremented. current_epoch: 0, epoch: 5\n",
            "epoch is incremented. current_epoch: 0, epoch: 5\n",
            "steps:  68% 1500/2222 [27:51<13:24,  1.11s/it, avr_loss=0.0654]\n",
            "saving checkpoint: /content/drive/MyDrive/Loras/playful_origins_v4/output_lora/playful_origins_v4_4-05.safetensors\n",
            "\n",
            "epoch 6/8\n",
            "epoch is incremented. current_epoch: 0, epoch: 6\n",
            "epoch is incremented. current_epoch: 0, epoch: 6\n",
            "epoch is incremented. current_epoch: 0, epoch: 6\n",
            "epoch is incremented. current_epoch: 0, epoch: 6\n",
            "epoch is incremented. current_epoch: 0, epoch: 6\n",
            "epoch is incremented. current_epoch: 0, epoch: 6\n",
            "epoch is incremented. current_epoch: 0, epoch: 6\n",
            "epoch is incremented. current_epoch: 0, epoch: 6\n",
            "steps:  81% 1800/2222 [33:25<07:50,  1.11s/it, avr_loss=0.0621]\n",
            "saving checkpoint: /content/drive/MyDrive/Loras/playful_origins_v4/output_lora/playful_origins_v4_4-06.safetensors\n",
            "\n",
            "epoch 7/8\n",
            "epoch is incremented. current_epoch: 0, epoch: 7\n",
            "epoch is incremented. current_epoch: 0, epoch: 7\n",
            "epoch is incremented. current_epoch: 0, epoch: 7\n",
            "epoch is incremented. current_epoch: 0, epoch: 7\n",
            "epoch is incremented. current_epoch: 0, epoch: 7\n",
            "epoch is incremented. current_epoch: 0, epoch: 7\n",
            "epoch is incremented. current_epoch: 0, epoch: 7\n",
            "epoch is incremented. current_epoch: 0, epoch: 7\n",
            "steps:  95% 2100/2222 [39:00<02:15,  1.11s/it, avr_loss=0.0603]\n",
            "saving checkpoint: /content/drive/MyDrive/Loras/playful_origins_v4/output_lora/playful_origins_v4_4-07.safetensors\n",
            "\n",
            "epoch 8/8\n",
            "epoch is incremented. current_epoch: 0, epoch: 8\n",
            "epoch is incremented. current_epoch: 0, epoch: 8\n",
            "epoch is incremented. current_epoch: 0, epoch: 8\n",
            "epoch is incremented. current_epoch: 0, epoch: 8\n",
            "epoch is incremented. current_epoch: 0, epoch: 8\n",
            "epoch is incremented. current_epoch: 0, epoch: 8\n",
            "epoch is incremented. current_epoch: 0, epoch: 8\n",
            "epoch is incremented. current_epoch: 0, epoch: 8\n",
            "steps: 100% 2222/2222 [41:16<00:00,  1.11s/it, avr_loss=0.0599]\n",
            "saving checkpoint: /content/drive/MyDrive/Loras/playful_origins_v4/output_lora/playful_origins_v4_4-08.safetensors\n",
            "model saved.\n",
            "steps: 100% 2222/2222 [41:17<00:00,  1.11s/it, avr_loss=0.0599]\n",
            "\n",
            "\u001b[1m✅ Done! Go download your Lora from Google Drive.\n",
            "There will be several files, you should try the latest version (the file with the largest number next to it)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U numpy==2.0.2 transformers==4.57.1 accelerate==1.11.0 diffusers==0.35.2 huggingface-hub==0.36.0 opencv-python==4.12.0.88 einops==0.8.1\n"
      ],
      "metadata": {
        "id": "8bdHncVMf62r",
        "outputId": "b3447173-b824-4e42-8ccb-c1a72c33f44c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==2.0.2\n",
            "  Downloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.57.1\n",
            "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==1.11.0\n",
            "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting diffusers==0.35.2\n",
            "  Downloading diffusers-0.35.2-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting huggingface-hub==0.36.0\n",
            "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting opencv-python==4.12.0.88\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Collecting einops==0.8.1\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (3.20.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2.32.4)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers==4.57.1)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers==4.57.1)\n",
            "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==1.11.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.11.0) (2.4.0+cu121)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.35.2) (8.7.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.35.2) (11.3.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.36.0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.36.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.36.0) (1.2.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate==1.11.0) (12.6.85)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers==0.35.2) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (2025.10.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.11.0) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=2.0.0->accelerate==1.11.0) (1.3.0)\n",
            "Downloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diffusers-0.35.2-py3-none-any.whl (4.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m127.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.8/485.8 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: safetensors, numpy, einops, opencv-python, huggingface-hub, tokenizers, diffusers, transformers, accelerate\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.4.2\n",
            "    Uninstalling safetensors-0.4.2:\n",
            "      Successfully uninstalled safetensors-0.4.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.7.0\n",
            "    Uninstalling einops-0.7.0:\n",
            "      Successfully uninstalled einops-0.7.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.8.1.78\n",
            "    Uninstalling opencv-python-4.8.1.78:\n",
            "      Successfully uninstalled opencv-python-4.8.1.78\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.1\n",
            "    Uninstalling huggingface-hub-0.20.1:\n",
            "      Successfully uninstalled huggingface-hub-0.20.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.25.0\n",
            "    Uninstalling diffusers-0.25.0:\n",
            "      Successfully uninstalled diffusers-0.25.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.36.2\n",
            "    Uninstalling transformers-4.36.2:\n",
            "      Successfully uninstalled transformers-4.36.2\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.25.0\n",
            "    Uninstalling accelerate-0.25.0:\n",
            "      Successfully uninstalled accelerate-0.25.0\n",
            "Successfully installed accelerate-1.11.0 diffusers-0.35.2 einops-0.8.1 huggingface-hub-0.36.0 numpy-2.0.2 opencv-python-4.12.0.88 safetensors-0.6.2 tokenizers-0.22.1 transformers-4.57.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "e8018a1448f34e36b38e14a233795d20"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "id": "miUzZbGEf1SB",
        "outputId": "f00c1211-ce62-441f-8be4-ccd9e01d0fba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBMUJ7BuvNcn"
      },
      "source": [
        "## *️⃣ Extras\n",
        "\n",
        "You can run these before starting the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sy9jU2yrdYar"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 🔮 Optimizer\n",
        "#@markdown If you run this cell you will change the optimizer used for training. The default will be `AdamW8bit` otherwise, which is recommended.<p>\n",
        "#@markdown * Dadapt and Prodigy manage learning rate automatically and are very good for small datasets. You can use it without changing anything else here.<p>\n",
        "#@markdown For Dadapt and Prodigy, the following values will be overriden if the box is checked:<p>\n",
        "#@markdown `learning_rate=0.5`, `network_alpha=network_dim`, `lr_scheduler=\"constant_with_warmup\"`, `lr_warmup_ratio=0.05`<p>\n",
        "#@markdown For Dadapt and Prodigy, if `optimizer_args` is left empty the default will be `decouple=True, weight_decay=0.01, betas=[0.9,0.999]`<p>\n",
        "#@markdown And additionally for Prodigy: `d_coef=2, use_bias_correction=True, safeguard_warmup=True`<p>\n",
        "optimizer = \"Prodigy\" #@param [\"AdamW8bit\", \"Prodigy\", \"DAdaptation\", \"DadaptAdam\", \"DadaptLion\", \"AdamW\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"AdaFactor\"]\n",
        "optimizer_args = \"\" #@param {type:\"string\"}\n",
        "splitter = \", \" if \", \" in optimizer_args else \",\"\n",
        "optimizer_args = [a.strip() for a in optimizer_args.split(splitter) if a]\n",
        "override_values_for_dadapt_and_prodigy = True #@param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd4916Eu1tb9"
      },
      "source": [
        "### 📚 Multiple folders in dataset\n",
        "Below is a template allowing you to define multiple folders in your dataset. You must include the location of each folder and you can set different number of repeats for each one. To add more folders simply copy and paste the sections starting with `[[datasets.subsets]]`.\n",
        "\n",
        "When enabling this, the number of repeats set in the main cell will be ignored, and the main folder set by the project name will also be ignored.\n",
        "\n",
        "You can make one of them a regularization folder by adding `is_reg = true`  \n",
        "You can also set different `keep_tokens`, `flip_aug`, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y037lagnJWmn"
      },
      "outputs": [],
      "source": [
        "custom_dataset = \"\"\"\n",
        "[[datasets]]\n",
        "resolution = 768\n",
        "batch_size = 2\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/content/drive/MyDrive/Loras/playful_origins_v4/dataset_v2/class1/PlayfulOrigins_00001\"\n",
        "num_repeats = 10\n",
        "keep_tokens = 1\n",
        "shuffle_caption = true\n",
        "caption_extension = \".txt\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W84Jxf-U2TIU"
      },
      "outputs": [],
      "source": [
        "custom_dataset = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-Yq5mNvcCy2l"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 🤓 Other\n",
        "#@markdown These are kept here for the few people that use them.\n",
        "\n",
        "#@markdown Weighted captions is a new feature that allows you to use (parentheses) to give more weight to certain tags in your dataset, same as in your webui prompts. <p>\n",
        "#@markdown Normal parentheses in your tags such as `(series names)` will need to be escaped like `\\(series names\\)`\n",
        "weighted_captions = False #@param {type:\"boolean\"}\n",
        "\n",
        "#markdown By enabling `adjust_tags`, you will let this colab modify your tags before running to automatically adjust to `weighted_captions` being on or off. <p>\n",
        "#markdown Then, you may increase `activation_tag_weight` to improve how effective your activation tag is.\n",
        "adjust_tags = False #param {type:\"boolean\"}\n",
        "activation_tag_weight = \"1.0\" #param [\"1.0\",\"1.1\",\"1.2\"]\n",
        "keep_tokens_weight = float(activation_tag_weight)\n",
        "\n",
        "#@markdown Here you can write a path in your Google Drive to load an existing Lora file to continue training on.<p>\n",
        "#@markdown **Warning:** It's not the same as one long training session. The epochs start from scratch, and it may have worse results.\n",
        "continue_from_lora = \"\" #@param {type:\"string\"}\n",
        "if continue_from_lora and not continue_from_lora.startswith(\"/content/drive/MyDrive\"):\n",
        "  import os\n",
        "  continue_from_lora = os.path.join(\"/content/drive/MyDrive\", continue_from_lora)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WDjkp4scvPgE"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 📂 Unzip dataset\n",
        "#@markdown It's much slower to upload individual files to your Drive, so you may want to upload a zip if you have your dataset in your computer.\n",
        "zip = \"/content/drive/MyDrive/my_dataset.zip\" #@param {type:\"string\"}\n",
        "extract_to = \"/content/drive/MyDrive/Loras/example/dataset\" #@param {type:\"string\"}\n",
        "\n",
        "import os, zipfile\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  print(\"📂 Connecting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip, 'r') as f:\n",
        "  f.extractall(extract_to)\n",
        "\n",
        "print(\"✅ Done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Verify dataset and model paths\n",
        "paths_to_check = [\n",
        "    \"/content/drive/MyDrive/Loras/playful_origins_v4/dataset_v2/class1/PlayfulOrigins_00001\",\n",
        "    \"/content/drive/MyDrive/Loras/playful_origins_v4/sd-nsfw-v1-5-realism.ckpt\",\n",
        "    \"/content/drive/MyDrive/Loras/playful_origins_v4/output_lora\"\n",
        "]\n",
        "\n",
        "for p in paths_to_check:\n",
        "    print(f\"Checking: {p}\")\n",
        "    if os.path.exists(p):\n",
        "        print(\"✅ Path found\\n\")\n",
        "    else:\n",
        "        print(\"❌ Missing — check spelling or mount issues\\n\")\n"
      ],
      "metadata": {
        "id": "wOX6zDOfccSP",
        "outputId": "aa5f1e95-77c2-42d4-b8d9-8eda5e411b8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Checking: /content/drive/MyDrive/Loras/playful_origins_v4/dataset_v2/class1/PlayfulOrigins_00001\n",
            "✅ Path found\n",
            "\n",
            "Checking: /content/drive/MyDrive/Loras/playful_origins_v4/sd-nsfw-v1-5-realism.ckpt\n",
            "✅ Path found\n",
            "\n",
            "Checking: /content/drive/MyDrive/Loras/playful_origins_v4/output_lora\n",
            "✅ Path found\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "aKWlpsG0jrX3",
        "outputId": "f3dc831e-910e-4552-de04-db30c9feb443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁PlayfulOrigins_00001 |   30 images |   30 captions |\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### 🔢 Count datasets\n",
        "#@markdown Google Drive makes it impossible to count the files in a folder, so this will show you the file counts in all folders and subfolders.\n",
        "folder = \"/content/drive/MyDrive/Loras/playful_origins_v4/dataset_v2/class1/PlayfulOrigins_00001\" #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"📂 Connecting to Google Drive...\\n\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "tree = {}\n",
        "exclude = (\"_logs\", \"/output\")\n",
        "for i, (root, dirs, files) in enumerate(os.walk(folder, topdown=True)):\n",
        "  dirs[:] = [d for d in dirs if all(ex not in d for ex in exclude)]\n",
        "  images = len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "  captions = len([f for f in files if f.lower().endswith(\".txt\")])\n",
        "  others = len(files) - images - captions\n",
        "  path = root[folder.rfind(\"/\")+1:]\n",
        "  tree[path] = None if not images else f\"{images:>4} images | {captions:>4} captions |\"\n",
        "  if tree[path] and others:\n",
        "    tree[path] += f\" {others:>4} other files\"\n",
        "\n",
        "pad = max(len(k) for k in tree)\n",
        "print(\"\\n\".join(f\"📁{k.ljust(pad)} | {v}\" for k, v in tree.items() if v))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDyqB2ytNN08"
      },
      "source": [
        "# 📈 Plot training results\n",
        "You can do this after running the trainer. You don't need this unless you know what you're doing.  \n",
        "The first cell below may fail to load all your logs. Keep trying the second cell until all data has loaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdogfLJ_NN08"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir={log_folder}/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NC0QOaXNN08"
      },
      "outputs": [],
      "source": [
        "from tensorboard import notebook\n",
        "notebook.display(port=6006, height=800)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ElevenSparks Angel Run Pre-Flight Check (v2) ---\n",
        "from google.colab import drive\n",
        "import os, glob\n",
        "\n",
        "print(\"🔄 Mounting Google Drive...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# --- Key Paths ---\n",
        "dataset_path = \"/content/drive/MyDrive/Loras/playful_origins_v4/dataset_v2/class1/PlayfulOrigins_00001\"\n",
        "model_path   = \"/content/drive/MyDrive/Loras/playful_origins_v4/sd-nsfw-v1-5-realism.ckpt\"\n",
        "output_path  = \"/content/drive/MyDrive/Loras/playful_origins_v4/output_lora\"\n",
        "\n",
        "# --- Verify Critical Paths ---\n",
        "print(\"\\n🔍 Verifying required paths...\\n\")\n",
        "for p in [dataset_path, model_path, output_path]:\n",
        "    print(f\"Checking: {p}\")\n",
        "    print(\"✅ Exists\\n\" if os.path.exists(p) else \"❌ MISSING — fix path before training!\\n\")\n",
        "\n",
        "# --- Count Dataset Files ---\n",
        "print(\"📊 Counting dataset contents...\\n\")\n",
        "\n",
        "# include .jpg, .jpeg, and .png\n",
        "img_files = (\n",
        "    glob.glob(os.path.join(dataset_path, \"*.jpg\")) +\n",
        "    glob.glob(os.path.join(dataset_path, \"*.jpeg\")) +\n",
        "    glob.glob(os.path.join(dataset_path, \"*.png\"))\n",
        ")\n",
        "txt_files = glob.glob(os.path.join(dataset_path, \"*.txt\"))\n",
        "\n",
        "print(f\"🖼️ Images found: {len(img_files)}\")\n",
        "print(f\"📝 Captions found: {len(txt_files)}\")\n",
        "\n",
        "if len(img_files) == len(txt_files) and len(img_files) > 0:\n",
        "    print(\"\\n✅ Dataset verified — matching image/caption pairs found.\")\n",
        "    print(\"✅ Base model and output directories accessible.\")\n",
        "    print(\"\\n🚀 Ready to launch the 2222-step Angel Run. Proceed to the START TRAINING cell.\")\n",
        "else:\n",
        "    # Show mismatches if any\n",
        "    img_names = {os.path.splitext(os.path.basename(f))[0] for f in img_files}\n",
        "    txt_names = {os.path.splitext(os.path.basename(f))[0] for f in txt_files}\n",
        "    missing_imgs = sorted(txt_names - img_names)\n",
        "    missing_txts = sorted(img_names - txt_names)\n",
        "\n",
        "    print(\"\\n⚠️ WARNING: Mismatch or missing files detected.\")\n",
        "    print(f\"Missing image files for captions: {missing_imgs}\")\n",
        "    print(f\"Missing caption files for images: {missing_txts}\")\n",
        "    print(\"\\nFix mismatched names or add missing pairs before training.\")\n"
      ],
      "metadata": {
        "id": "Jyqw08Atd02V",
        "outputId": "3781550a-52e5-4dfc-d52b-a8495a0fe24f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "\n",
            "🔍 Verifying required paths...\n",
            "\n",
            "Checking: /content/drive/MyDrive/Loras/playful_origins_v4/dataset_v2/class1/PlayfulOrigins_00001\n",
            "✅ Exists\n",
            "\n",
            "Checking: /content/drive/MyDrive/Loras/playful_origins_v4/sd-nsfw-v1-5-realism.ckpt\n",
            "✅ Exists\n",
            "\n",
            "Checking: /content/drive/MyDrive/Loras/playful_origins_v4/output_lora\n",
            "✅ Exists\n",
            "\n",
            "📊 Counting dataset contents...\n",
            "\n",
            "🖼️ Images found: 30\n",
            "📝 Captions found: 30\n",
            "\n",
            "✅ Dataset verified — matching image/caption pairs found.\n",
            "✅ Base model and output directories accessible.\n",
            "\n",
            "🚀 Ready to launch the 2222-step Angel Run. Proceed to the START TRAINING cell.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}