{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GTmycology/dreambooth-colab/blob/main/fast-DreamBooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEsNHTtVlbkV"
      },
      "source": [
        "# **Colab Pro notebook from https://github.com/TheLastBen/fast-stable-diffusion. [ComfyUI Colab](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast_stable_diffusion_ComfyUI.ipynb)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "A4Bae3VP6UsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5bca0f4-7bf1-4fb4-b5c4-3f9f9696c220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/Loras/playful_origins_v4\"\n",
        "INSTANCE_DIR = f\"{BASE_DIR}/dataset\"\n",
        "CAPTIONS_DIR = f\"{BASE_DIR}/captions\"  # keep for future use\n",
        "OUTPUT_DIR = f\"{BASE_DIR}/output\"\n",
        "\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
        "PT = \"a photo of [your-unique-identifier] person\"\n",
        "\n",
        "# Create folders if they don't exist\n",
        "for d in [INSTANCE_DIR, CAPTIONS_DIR, OUTPUT_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "print(\"✅ Path check complete:\")\n",
        "print(\"Instance dir:\", INSTANCE_DIR, \"->\", os.path.exists(INSTANCE_DIR))\n",
        "print(\"Captions dir:\", CAPTIONS_DIR, \"->\", os.path.exists(CAPTIONS_DIR))\n",
        "print(\"Output dir:\", OUTPUT_DIR, \"->\", os.path.exists(OUTPUT_DIR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF9AD2SPKCjU",
        "outputId": "81743622-b93b-443a-e2d2-c123ca540358"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Path check complete:\n",
            "Instance dir: /content/drive/MyDrive/Loras/playful_origins_v4/dataset -> True\n",
            "Captions dir: /content/drive/MyDrive/Loras/playful_origins_v4/captions -> True\n",
            "Output dir: /content/drive/MyDrive/Loras/playful_origins_v4/output -> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R \"/content/drive/MyDrive/Loras/playful_origins_v4\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eErBzwCoSkjL",
        "outputId": "0e806a2a-3f85-40d0-9cd4-9eae5990723b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Loras/playful_origins_v4:\n",
            "captions  dataset  output\n",
            "\n",
            "/content/drive/MyDrive/Loras/playful_origins_v4/captions:\n",
            "\n",
            "/content/drive/MyDrive/Loras/playful_origins_v4/dataset:\n",
            "\n",
            "/content/drive/MyDrive/Loras/playful_origins_v4/output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder = \"/content/drive/MyDrive/Loras/playful_origins_v4/dataset\"\n",
        "files = os.listdir(folder)\n",
        "print(f\"Found {len(files)} files in dataset:\")\n",
        "for f in files[:10]:\n",
        "    print(\"  \", f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NOQWnmKSPQY",
        "outputId": "bb3dbea3-0911-4542-d311-800289dc3bfe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 files in dataset:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF2T8K6ZWqWk",
        "outputId": "916eb991-993f-4666-9dae-96a2658c6dba"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct  9 00:46:40 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "%cd /content\n"
      ],
      "metadata": {
        "id": "KdZL1oa8fWtA",
        "outputId": "ab0cfc01-13df-44ec-b10b-06d6cc9ededa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\" -O /content/model.safetensors\n",
        "!wget -q -O /content/config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "\n",
        "# Convert the safetensors model to diffusers format\n",
        "!mkdir -p /content/stable-diffusion-v1-5\n",
        "!python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  --checkpoint_path /content/model.safetensors \\\n",
        "  --dump_path /content/stable-diffusion-v1-5 \\\n",
        "  --original_config_file /content/config.yaml \\\n",
        "  --from_safetensors\n"
      ],
      "metadata": {
        "id": "Kc4Bg_CHfZdB",
        "outputId": "cfa3e26b-58de-497d-dcb9-717645d7e8cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.27.2 transformers accelerate safetensors --upgrade\n"
      ],
      "metadata": {
        "id": "wyjJ--GcflKB",
        "outputId": "3223d42f-c4eb-47c3-e941-bbbc06df20de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers==0.27.2\n",
            "  Downloading diffusers-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (0.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (0.35.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (2.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (11.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.2) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->diffusers==0.27.2) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading diffusers-0.27.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m136.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diffusers, transformers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.35.1\n",
            "    Uninstalling diffusers-0.35.1:\n",
            "      Successfully uninstalled diffusers-0.35.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.2\n",
            "    Uninstalling transformers-4.56.2:\n",
            "      Successfully uninstalled transformers-4.56.2\n",
            "Successfully installed diffusers-0.27.2 transformers-4.57.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the conversion script manually (TheLastBen version)\n",
        "!wget -q -O /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convert_original_stable_diffusion_to_diffusers.py\n",
        "\n",
        "# Make sure your output folder exists\n",
        "!mkdir -p /content/stable-diffusion-v1-5\n",
        "\n",
        "# Convert the model to diffusers format\n",
        "!python /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  --checkpoint_path /content/model.safetensors \\\n",
        "  --dump_path /content/stable-diffusion-v1-5 \\\n",
        "  --original_config_file /content/config.yaml \\\n",
        "  --from_safetensors\n",
        "\n"
      ],
      "metadata": {
        "id": "9fhhnKXzf_Yz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/\n",
        "\n"
      ],
      "metadata": {
        "id": "j9oha-RMgwqH",
        "outputId": "741d26ff-9596-4b7c-de32-cba42f63f1f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4.0G\n",
            "-rw-r--r-- 1 root root 1.9K Oct  9 01:03 config.yaml\n",
            "-rw-r--r-- 1 root root    0 Oct  9 01:06 convert_original_stable_diffusion_to_diffusers.py\n",
            "drwxr-xr-x 3 root root 4.0K Oct  9 00:01 drive\n",
            "drwx------ 5 root root 4.0K Oct  9 00:01 gdrive\n",
            "-rw-r--r-- 1 root root 4.0G Oct  9 01:02 model.safetensors\n",
            "drwxr-xr-x 2 root root 4.0K Oct  9 00:03 __pycache__\n",
            "drwxr-xr-x 1 root root 4.0K Oct  7 13:38 sample_data\n",
            "-rw-r--r-- 1 root root 7.7K Oct  9 00:03 smart_crop.py\n",
            "drwxr-xr-x 3 root root 4.0K Oct  9 00:58 stable-diffusion-custom\n",
            "drwxr-xr-x 2 root root 4.0K Oct  9 01:03 stable-diffusion-v1-5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the working conversion script from Hugging Face diffusers\n",
        "!wget -O /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "\n",
        "# Make sure it’s executable\n",
        "!chmod +x /content/convert_original_stable_diffusion_to_diffusers.py\n"
      ],
      "metadata": {
        "id": "ZmoBgaHbif4t",
        "outputId": "8831898a-ac3d-496a-8e44-d6cbcde26463",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-09 01:16:00--  https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7020 (6.9K) [text/plain]\n",
            "Saving to: ‘/content/convert_original_stable_diffusion_to_diffusers.py’\n",
            "\n",
            "/content/convert_or 100%[===================>]   6.86K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-09 01:16:00 (41.8 MB/s) - ‘/content/convert_original_stable_diffusion_to_diffusers.py’ saved [7020/7020]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  --checkpoint_path /content/model.safetensors \\\n",
        "  --dump_path /content/stable-diffusion-v1-5 \\\n",
        "  --original_config_file /content/config.yaml \\\n",
        "  --from_safetensors\n"
      ],
      "metadata": {
        "id": "FlS2EpnDilue",
        "outputId": "d92ce843-d1cd-4b5d-c52a-69d88b12fd60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-09 01:16:47.093415: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759972607.118615    1011 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759972607.125979    1011 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759972607.145291    1011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759972607.145334    1011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759972607.145339    1011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759972607.145343    1011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/convert_original_stable_diffusion_to_diffusers.py\", line 160, in <module>\n",
            "    pipe = download_from_original_stable_diffusion_ckpt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/stable_diffusion/convert_from_ckpt.py\", line 1273, in download_from_original_stable_diffusion_ckpt\n",
            "    checkpoint = safe_load(checkpoint_path_or_dict, device=\"cpu\")\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/safetensors/torch.py\", line 381, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: No such file or directory: /content/model.safetensors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content\n",
        "\n"
      ],
      "metadata": {
        "id": "6vOHKtSni35B",
        "outputId": "75a48472-bfa7-4388-f5f5-3aa6f3dc7b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12K\n",
            "-rwxr-xr-x 1 root root 6.9K Oct  9 01:16 convert_original_stable_diffusion_to_diffusers.py\n",
            "drwxr-xr-x 1 root root 4.0K Oct  7 13:38 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/stable-diffusion-v1-5\n",
        "!python /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  --checkpoint_path /content/model.safetensors \\\n",
        "  --dump_path /content/stable-diffusion-v1-5 \\\n",
        "  --original_config_file /content/config.yaml \\\n",
        "  --from_safetensors\n"
      ],
      "metadata": {
        "id": "tBqY6UhXgLHl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "id": "GaR8j3SBmtdb",
        "outputId": "98f92873-f825-45f0-81e1-13d439b27141",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=87f6f5b4687591bdf6b621b035bc9125ef3425fc00a42bd4bb648e4afc7f8027\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.27.2 transformers==4.37.2 accelerate==0.29.3 safetensors==0.4.3"
      ],
      "metadata": {
        "id": "PQ0UudYe4JnF",
        "outputId": "b7f281fb-7c6c-426f-8981-43ca02bc643d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers==0.27.2\n",
            "  Downloading diffusers-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting transformers==4.37.2\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.29.3\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting safetensors==0.4.3\n",
            "  Downloading safetensors-0.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (0.35.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (2.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (11.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (6.0.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.2)\n",
            "  Downloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.29.3) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.29.3) (2.8.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.2) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.4.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->diffusers==0.27.2) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (3.0.3)\n",
            "Downloading diffusers-0.27.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: safetensors, tokenizers, diffusers, transformers, accelerate\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.6.2\n",
            "    Uninstalling safetensors-0.6.2:\n",
            "      Successfully uninstalled safetensors-0.6.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.35.1\n",
            "    Uninstalling diffusers-0.35.1:\n",
            "      Successfully uninstalled diffusers-0.35.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.2\n",
            "    Uninstalling transformers-4.56.2:\n",
            "      Successfully uninstalled transformers-4.56.2\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.10.1\n",
            "    Uninstalling accelerate-1.10.1:\n",
            "      Successfully uninstalled accelerate-1.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.29.3 diffusers-0.27.2 safetensors-0.4.3 tokenizers-0.15.2 transformers-4.37.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n"
      ],
      "metadata": {
        "id": "Kzs8iI5u4sTj",
        "outputId": "ffaf206d-ebf7-475a-d703-3030517f6673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-09 02:53:01--  https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7020 (6.9K) [text/plain]\n",
            "Saving to: ‘/content/convert_original_stable_diffusion_to_diffusers.py’\n",
            "\n",
            "/content/convert_or 100%[===================>]   6.86K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-09 02:53:01 (22.2 MB/s) - ‘/content/convert_original_stable_diffusion_to_diffusers.py’ saved [7020/7020]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/convert_original_stable_diffusion_to_diffusers.py\n"
      ],
      "metadata": {
        "id": "YwTNKRjJ4xRQ",
        "outputId": "67d47341-3c0b-4ee5-c3b9-ef02c568160e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rwxr-xr-x 1 root root 6.9K Oct  9 02:53 /content/convert_original_stable_diffusion_to_diffusers.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content\n",
        "\n"
      ],
      "metadata": {
        "id": "ubB6xzCX5Jz0",
        "outputId": "381e04b0-3ab4-42be-e18f-dafbe332cf68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 7.2G\n",
            "-rwxr-xr-x 1 root root 6.9K Oct  9 02:53  convert_original_stable_diffusion_to_diffusers.py\n",
            "-rw-r--r-- 1 root root 7.0K Oct  9 02:22 'det (1).py'\n",
            "-rw-r--r-- 1 root root 7.0K Oct  9 01:34  det.py\n",
            "-rw-r--r-- 1 root root 7.2G Oct  9 01:24  model.safetensors\n",
            "drwxr-xr-x 1 root root 4.0K Oct  7 13:38  sample_data\n",
            "drwxr-xr-x 2 root root 4.0K Oct  9 02:54  stable-diffusion-custom\n",
            "drwxr-xr-x 9 root root 4.0K Oct  9 01:28  stable-diffusion-v1-5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "MODEL_PATH = \"/content/model.safetensors\"\n",
        "sftnsr = \"--from_safetensors\"\n",
        "\n",
        "print(\"Custom model version set manually to 1.5 — skipping detection.\")\n",
        "clear_output()\n",
        "\n",
        "# Convert from .safetensors to Diffusers\n",
        "!wget -q -O /content/config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "!python /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  --checkpoint_path \"$MODEL_PATH\" \\\n",
        "  --dump_path /content/stable-diffusion-custom \\\n",
        "  --original_config_file /content/config.yaml \\\n",
        "  $sftnsr\n",
        "!rm /content/config.yaml\n",
        "\n",
        "# Confirm conversion result\n",
        "if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "    clear_output()\n",
        "    print(\"✅ DONE! Model converted successfully.\")\n",
        "else:\n",
        "    print(\"❌ Conversion failed — check paths or file type.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zlQEfj_t5-22",
        "outputId": "06f58ae5-29e7-49aa-bfea-77741ae16471",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2025-10-09 03:06:13.760905: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759979173.785594   27511 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759979173.793160   27511 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759979173.811316   27511 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759979173.811364   27511 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759979173.811369   27511 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759979173.811376   27511 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.12/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "In this conversion only the non-EMA weights are extracted. If you want to instead extract the EMA weights (usually better for inference), please make sure to add the `--extract_ema` flag.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/convert_original_stable_diffusion_to_diffusers.py\", line 160, in <module>\n",
            "    pipe = download_from_original_stable_diffusion_ckpt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/stable_diffusion/convert_from_ckpt.py\", line 1687, in download_from_original_stable_diffusion_ckpt\n",
            "    pipe = pipeline_class(\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 237, in __init__\n",
            "    self.register_modules(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py\", line 569, in register_modules\n",
            "    not_compiled_module = _unwrap_model(module)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py\", line 286, in _unwrap_model\n",
            "    from peft import PeftModel\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/__init__.py\", line 17, in <module>\n",
            "    from .auto import (\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/auto.py\", line 31, in <module>\n",
            "    from .config import PeftConfig\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/config.py\", line 24, in <module>\n",
            "    from .utils import CONFIG_NAME, PeftType, TaskType\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/utils/__init__.py\", line 16, in <module>\n",
            "    from .loftq_utils import replace_lora_weights_loftq\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/utils/loftq_utils.py\", line 25, in <module>\n",
            "    from accelerate.utils.memory import clear_device_cache\n",
            "ImportError: cannot import name 'clear_device_cache' from 'accelerate.utils.memory' (/usr/local/lib/python3.12/dist-packages/accelerate/utils/memory.py)\n",
            "❌ Conversion failed — check paths or file type.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate==0.21.0\n"
      ],
      "metadata": {
        "id": "BKgsKfZp8Pp0",
        "outputId": "763f630b-9a37-453d-9ded-7fc6e965417b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate==0.21.0\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.21.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.21.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.21.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate==0.21.0) (6.0.3)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.21.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (3.0.3)\n",
            "Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.29.3\n",
            "    Uninstalling accelerate-0.29.3:\n",
            "      Successfully uninstalled accelerate-0.29.3\n",
            "Successfully installed accelerate-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface-hub==0.25.2 diffusers==0.25.0 transformers==4.37.2 accelerate==0.29.3 safetensors==0.4.3\n"
      ],
      "metadata": {
        "id": "nocijiSY7Q0Z",
        "outputId": "b0457a18-8202-4aea-ebad-1fb53a4548d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface-hub==0.25.2\n",
            "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting diffusers==0.25.0\n",
            "  Downloading diffusers-0.25.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers==4.37.2 in /usr/local/lib/python3.12/dist-packages (4.37.2)\n",
            "Requirement already satisfied: accelerate==0.29.3 in /usr/local/lib/python3.12/dist-packages (0.29.3)\n",
            "Requirement already satisfied: safetensors==0.4.3 in /usr/local/lib/python3.12/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.25.2) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.25.2) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.25.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.25.2) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.25.2) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.25.2) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.25.2) (4.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.25.0) (8.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers==0.25.0) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.25.0) (2024.11.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.25.0) (11.3.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (0.15.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.29.3) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.29.3) (2.8.0+cu126)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.4.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->diffusers==0.25.0) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.25.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.25.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.25.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.25.2) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (3.0.3)\n",
            "Downloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diffusers-0.25.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub, diffusers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.27.2\n",
            "    Uninstalling diffusers-0.27.2:\n",
            "      Successfully uninstalled diffusers-0.27.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.47.2 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.25.2 which is incompatible.\n",
            "sentence-transformers 5.1.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed diffusers-0.25.0 huggingface-hub-0.25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show diffusers huggingface-hub | grep Version\n"
      ],
      "metadata": {
        "id": "F4CDQ7_v7n6T",
        "outputId": "5f2e3932-bbb1-4842-820e-dc2efff13adf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version: 0.25.0\n",
            "Version: 0.25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface-hub==0.19.4\n"
      ],
      "metadata": {
        "id": "yFaDt98X6fw1",
        "outputId": "f8f86730-a1a2-46c8-c151-b8a7d7359ea7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface-hub==0.19.4\n",
            "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.19.4) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.19.4) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.19.4) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.19.4) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.19.4) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.19.4) (4.15.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.19.4) (25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.19.4) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.19.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.19.4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.19.4) (2025.8.3)\n",
            "Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.35.3\n",
            "    Uninstalling huggingface-hub-0.35.3:\n",
            "      Successfully uninstalled huggingface-hub-0.35.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "diffusers 0.27.2 requires huggingface-hub>=0.20.2, but you have huggingface-hub 0.19.4 which is incompatible.\n",
            "gradio 5.47.2 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.19.4 which is incompatible.\n",
            "sentence-transformers 5.1.1 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.19.4 which is incompatible.\n",
            "sentence-transformers 5.1.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\n",
            "peft 0.17.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.19.4 which is incompatible.\n",
            "datasets 4.0.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.19.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.19.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3SsbIlxw66N"
      },
      "source": [
        "# Model Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "d1169f63-485f-4729-8921-4bd80222d70b",
        "id": "tYH6amOweUtV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom model version set manually to 1.5 — skipping detection.\n",
            "python3: can't open file '/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py': [Errno 2] No such file or directory\n",
            "rm: cannot remove '/content/stable-diffusion-custom': No such file or directory\n",
            "rm: cannot remove '/content/stable-diffusion-v1-5': Is a directory\n",
            "❌ Conversion error — retrying...\n",
            "❌ Conversion error — retrying...\n",
            "❌ Conversion error — retrying...\n",
            "❌ Conversion error — retrying...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2786724354.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'❌ Conversion error — retrying...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;31m# (No `else:` here — we’re done with this conditional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "import wget\n",
        "from subprocess import check_output\n",
        "import urllib.request\n",
        "import requests\n",
        "import base64\n",
        "from gdown.download import get_url_from_gdrive_confirmation\n",
        "from urllib.parse import urlparse, parse_qs, unquote\n",
        "from urllib.request import urlopen, Request\n",
        "import re\n",
        "\n",
        "def getsrc(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    if parsed_url.netloc == 'civitai.com':\n",
        "        src='civitai'\n",
        "    elif parsed_url.netloc == 'drive.google.com':\n",
        "        src='gdrive'\n",
        "    elif parsed_url.netloc == 'huggingface.co':\n",
        "        src='huggingface'\n",
        "    else:\n",
        "        src='others'\n",
        "    return src\n",
        "\n",
        "\n",
        "\n",
        "def get_name(url, gdrive):\n",
        "    if not gdrive:\n",
        "        response = requests.get(url, allow_redirects=False)\n",
        "        if \"Location\" in response.headers:\n",
        "            redirected_url = response.headers[\"Location\"]\n",
        "            quer = parse_qs(urlparse(redirected_url).query)\n",
        "            if \"response-content-disposition\" in quer:\n",
        "                disp_val = quer[\"response-content-disposition\"][0].split(\";\")\n",
        "                for vals in disp_val:\n",
        "                    if vals.strip().startswith(\"filename=\"):\n",
        "                        filenm=unquote(vals.split(\"=\", 1)[1].strip())\n",
        "                        return filenm.replace(\"\\\"\",\"\")\n",
        "    else:\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\"}\n",
        "        lnk=\"https://drive.google.com/uc?id={id}&export=download\".format(id=url[url.find(\"/d/\")+3:url.find(\"/view\")])\n",
        "        res = requests.session().get(lnk, headers=headers, stream=True, verify=True)\n",
        "        res = requests.session().get(get_url_from_gdrive_confirmation(res.text), headers=headers, stream=True, verify=True)\n",
        "        content_disposition = six.moves.urllib_parse.unquote(res.headers[\"Content-Disposition\"])\n",
        "        filenm = re.search('attachment; filename=\"(.*?)\"', content_disposition).groups()[0]\n",
        "        return filenm\n",
        "\n",
        "#@markdown - Skip this cell if you are loading a previous session that contains a trained model.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Model_Version = \"1.5\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
        "\n",
        "#@markdown - Choose which version to finetune.\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  os.chdir('/content')\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Path_to_HuggingFace= \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Load and finetune a model from Hugging Face, use the format \"profile/model\" like : runwayml/stable-diffusion-v1-5\n",
        "#@markdown - If the custom model is private or requires a token, create token.txt containing the token in \"Fast-Dreambooth\" folder in your gdrive.\n",
        "\n",
        "MODEL_PATH = \"/content/stable-diffusion-v1-5\" #@param {type:\"string\"}\n",
        "\n",
        "MODEL_LINK = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if os.path.exists('/content/gdrive/MyDrive/Fast-Dreambooth/token.txt'):\n",
        "  with open(\"/content/gdrive/MyDrive/Fast-Dreambooth/token.txt\") as f:\n",
        "     token = f.read()\n",
        "  authe=f'https://USER:{token}@'\n",
        "else:\n",
        "  authe=\"https://\"\n",
        "\n",
        "def downloadmodel():\n",
        "\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "  clear_output()\n",
        "\n",
        "  os.chdir('/content')\n",
        "\n",
        "\n",
        "  print(\"\u001b[1;32mDownloading the model...\")\n",
        "  !wget -q \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\" -O model.safetensors\n",
        "\n",
        "  if os.path.exists('/content/model.safetensors'):\n",
        "      !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "      clear_output()\n",
        "      !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /content/model.safetensors --dump_path /content/stable-diffusion-v1-5 --original_config_file config.yaml --from_safetensors\n",
        "      !rm config.yaml\n",
        "      clear_output()\n",
        "      os.chdir('/content/stable-diffusion-v1-5')\n",
        "      !wget -q -O vae/diffusion_pytorch_model.bin https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.bin\n",
        "      !rm model_index.json\n",
        "      clear_output()\n",
        "      time.sleep(1)\n",
        "      wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "      os.chdir('/content')\n",
        "\n",
        "\n",
        "def newdownloadmodel():\n",
        "\n",
        "  os.chdir('/content')\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v2-768\n",
        "  os.chdir('/content/stable-diffusion-v2-768')\n",
        "  !git config --global init.defaultBranch main\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\\n!*.fp16.bin\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  !rm -r /content/stable-diffusion-v2-768/.git\n",
        "  os.chdir('/content')\n",
        "  clear_output()\n",
        "  print('\u001b[1;32mDONE !')\n",
        "\n",
        "\n",
        "def newdownloadmodelb():\n",
        "\n",
        "  os.chdir('/content')\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v2-512\n",
        "  os.chdir('/content/stable-diffusion-v2-512')\n",
        "  !git config --global init.defaultBranch main\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\\n!*.fp16.bin\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  !rm -r /content/stable-diffusion-v2-512/.git\n",
        "  os.chdir('/content')\n",
        "  clear_output()\n",
        "  print('\u001b[1;32mDONE !')\n",
        "\n",
        "\n",
        "if Path_to_HuggingFace != \"\":\n",
        "  if authe==\"https://\":\n",
        "    textenc= f\"{authe}huggingface.co/{Path_to_HuggingFace}/resolve/main/text_encoder/pytorch_model.bin\"\n",
        "    txtenc_size=urllib.request.urlopen(textenc).info().get('Content-Length', None)\n",
        "  else:\n",
        "    textenc= f\"https://huggingface.co/{Path_to_HuggingFace}/resolve/main/text_encoder/pytorch_model.bin\"\n",
        "    req=urllib.request.Request(textenc)\n",
        "    req.add_header('Authorization', f'Bearer {token}')\n",
        "    txtenc_size=urllib.request.urlopen(req).info().get('Content-Length', None)\n",
        "  if int(txtenc_size)> 670000000 :\n",
        "    if os.path.exists('/content/stable-diffusion-custom'):\n",
        "      !rm -r /content/stable-diffusion-custom\n",
        "    clear_output()\n",
        "    os.chdir('/content')\n",
        "    clear_output()\n",
        "    print(\"\u001b[1;32mV2\")\n",
        "    !mkdir /content/stable-diffusion-custom\n",
        "    os.chdir('/content/stable-diffusion-custom')\n",
        "    !git config --global init.defaultBranch main\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"{authe}huggingface.co/{Path_to_HuggingFace}\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "      !rm -r /content/stable-diffusion-custom/.git\n",
        "      os.chdir('/content')\n",
        "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
        "      clear_output()\n",
        "      print('\u001b[1;32mDONE !')\n",
        "    else:\n",
        "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "            print('\u001b[1;31mCheck the link you provided')\n",
        "            time.sleep(5)\n",
        "  else:\n",
        "    if os.path.exists('/content/stable-diffusion-custom'):\n",
        "      !rm -r /content/stable-diffusion-custom\n",
        "    clear_output()\n",
        "    os.chdir('/content')\n",
        "    clear_output()\n",
        "    print(\"\u001b[1;32mV1\")\n",
        "    !mkdir /content/stable-diffusion-custom\n",
        "    os.chdir('/content/stable-diffusion-custom')\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"{authe}huggingface.co/{Path_to_HuggingFace}\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "      !rm -r /content/stable-diffusion-custom/.git\n",
        "      !rm model_index.json\n",
        "      time.sleep(1)\n",
        "      wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "      os.chdir('/content')\n",
        "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
        "      clear_output()\n",
        "      print('\u001b[1;32mDONE !')\n",
        "    else:\n",
        "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "            print('\u001b[1;31mCheck the link you provided')\n",
        "            time.sleep(5)\n",
        "\n",
        "elif MODEL_PATH !=\"\":\n",
        "\n",
        "  modelname=os.path.basename(MODEL_PATH)\n",
        "  sftnsr=\"\"\n",
        "  if modelname.split('.')[-1]=='safetensors':\n",
        "    sftnsr=\"--from_safetensors\"\n",
        "\n",
        "%cd /content\n",
        "clear_output()\n",
        "\n",
        "if os.path.exists(str(MODEL_PATH)):\n",
        "    # Skip model version detection, set manually\n",
        "    Custom_Model_Version = \"1.5\"\n",
        "    print(\"Custom model version set manually to 1.5 — skipping detection.\")\n",
        "\n",
        "    if Custom_Model_Version == '1.5':\n",
        "        !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "        !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "            --checkpoint_path \"$MODEL_PATH\" \\\n",
        "            --dump_path /content/stable-diffusion-custom \\\n",
        "            --original_config_file /content/config.yaml \\\n",
        "            $sftnsr\n",
        "        !rm /content/config.yaml\n",
        "\n",
        "    elif Custom_Model_Version == 'V2.1-512px':\n",
        "        !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
        "        !python /content/convertodiff.py \"$MODEL_PATH\" /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n",
        "        !rm /content/convertodiff.py\n",
        "\n",
        "    elif Custom_Model_Version == 'V2.1-768px':\n",
        "        !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
        "        !python /content/convertodiff.py \"$MODEL_PATH\" /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n",
        "        !rm /content/convertodiff.py\n",
        "\n",
        "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "        clear_output()\n",
        "        MODEL_NAME = \"/content/stable-diffusion-custom\"\n",
        "        print('✅ DONE! Model converted successfully.')\n",
        "    else:\n",
        "        !rm -r /content/stable-diffusion-custom\n",
        "        !rm \"$MODEL_PATH\"\n",
        "        while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "            print('❌ Conversion error — retrying...')\n",
        "            time.sleep(5)\n",
        "\n",
        "# (No `else:` here — we’re done with this conditional)\n",
        "\n",
        "\n",
        "\n",
        "elif MODEL_LINK !=\"\":\n",
        "    os.chdir('/content')\n",
        "\n",
        "    src=getsrc(MODEL_LINK)\n",
        "\n",
        "    if src=='civitai':\n",
        "       modelname=get_name(str(MODEL_LINK), False)\n",
        "    elif src=='gdrive':\n",
        "       modelname=get_name(str(MODEL_LINK), True)\n",
        "    else:\n",
        "       modelname=os.path.basename(str(MODEL_LINK))\n",
        "\n",
        "    sftnsr=\"\"\n",
        "    if modelname.split('.')[-1]!='safetensors':\n",
        "      modelnm=\"model.ckpt\"\n",
        "    else:\n",
        "      modelnm=\"model.safetensors\"\n",
        "      sftnsr=\"--from_safetensors\"\n",
        "\n",
        "    !gdown --fuzzy \"$MODEL_LINK\" -O $modelnm\n",
        "\n",
        "if os.path.exists(modelnm):\n",
        "    if os.path.getsize(modelnm) > 1810671599:\n",
        "        # Skip automatic detection and set manually\n",
        "        Custom_Model_Version = \"1.5\"\n",
        "        print(Custom_Model_Version, \"set manually — skipping automatic detection\")\n",
        "\n",
        "        if Custom_Model_Version == '1.5':\n",
        "            !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "            !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $modelnm --dump_path stable-diffusion-custom --original_config_file config.yaml $sftnsr\n",
        "            !rm config.yaml\n",
        "\n",
        "        elif Custom_Model_Version == 'V2.1-512px':\n",
        "            !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
        "            !python /content/convertodiff.py $modelnm /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n",
        "            !rm convertodiff.py\n",
        "\n",
        "        elif Custom_Model_Version == 'V2.1-768px':\n",
        "            !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
        "            !python /content/convertodiff.py $modelnm /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n",
        "            !rm convertodiff.py\n",
        "\n",
        "        if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "            clear_output()\n",
        "            MODEL_NAME = \"/content/stable-diffusion-custom\"\n",
        "            print('✅ DONE!')\n",
        "        else:\n",
        "            !rm -r stable-diffusion-custom\n",
        "            !rm $modelnm\n",
        "            while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "                print('⚠️ Conversion error')\n",
        "                time.sleep(5)\n",
        "    else:\n",
        "        while os.path.getsize(modelnm) < 1810671599:\n",
        "            print('⚠️ Wrong link, check that the link is valid')\n",
        "            time.sleep(5)\n",
        "\n",
        "else:\n",
        "  if Model_Version==\"1.5\":\n",
        "    if not os.path.exists('/content/stable-diffusion-v1-5/unet'):\n",
        "      downloadmodel()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "      print(\"\u001b[1;32mv1.5 model downloaded\")\n",
        "    else:\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "      print(\"\u001b[1;32mThe v1.5 model already exists, using this model.\")\n",
        "  elif Model_Version==\"V2.1-512px\":\n",
        "    if not os.path.exists('/content/stable-diffusion-v2-512'):\n",
        "      newdownloadmodelb()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n",
        "    else:\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n",
        "      print(\"\u001b[1;32mThe v2-512px model already exists, using this model.\")\n",
        "  elif Model_Version==\"V2.1-768px\":\n",
        "    if not os.path.exists('/content/stable-diffusion-v2-768'):\n",
        "      newdownloadmodel()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n",
        "    else:\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n",
        "      print(\"\u001b[1;32mThe v2-768px model already exists, using this model.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INSTANCE_DIR = \"/content/gdrive/MyDrive/Loras/playful_origins_v4/dataset\"\n",
        "CAPTIONS_DIR = \"/content/gdrive/MyDrive/Loras/playful_origins_v4/captions\"\n",
        "OUTPUT_DIR   = \"/content/gdrive/MyDrive/Loras/playful_origins_v4/output\"\n",
        "\n",
        "print(\"✅ Paths updated:\")\n",
        "print(\"INSTANCE_DIR:\", INSTANCE_DIR)\n",
        "print(\"CAPTIONS_DIR:\", CAPTIONS_DIR)\n",
        "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF9fxKthYPNs",
        "outputId": "e1337f46-8827-4f6e-95fe-dbeeb2c30cb3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Paths updated:\n",
            "INSTANCE_DIR: /content/gdrive/MyDrive/Loras/playful_origins_v4/dataset\n",
            "CAPTIONS_DIR: /content/gdrive/MyDrive/Loras/playful_origins_v4/captions\n",
            "OUTPUT_DIR: /content/gdrive/MyDrive/Loras/playful_origins_v4/output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"$INSTANCE_DIR\" | head -n 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQOFZvUlYXU2",
        "outputId": "ca13c47d-1225-4343-a32f-34b9c9c8a620"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMG_6276.jpg\n",
            "IMG_6276.txt\n",
            "IMG_7935.PNG\n",
            "IMG_7935.txt\n",
            "IMG_7936.PNG\n",
            "IMG_7936.txt\n",
            "IMG_7937.JPG\n",
            "IMG_7937.txt\n",
            "IMG_7940.png\n",
            "IMG_7940.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tN76Cj5P3RL"
      },
      "source": [
        "# Dreambooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A1B299g-_VJo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from os import listdir\n",
        "from os.path import isfile\n",
        "from subprocess import check_output\n",
        "import wget\n",
        "import time\n",
        "\n",
        "#@markdown #Create/Load a Session\n",
        "\n",
        "try:\n",
        "  MODEL_NAME\n",
        "  pass\n",
        "except:\n",
        "  MODEL_NAME=\"\"\n",
        "\n",
        "PT=\"\"\n",
        "\n",
        "Session_Name = \"\" #@param{type: 'string'}\n",
        "while Session_Name==\"\":\n",
        "  print('\u001b[1;31mInput the Session Name:')\n",
        "  Session_Name=input('')\n",
        "Session_Name=Session_Name.replace(\" \",\"_\")\n",
        "\n",
        "#@markdown - Enter the session name, it if it exists, it will load it, otherwise it'll create an new session.\n",
        "\n",
        "Session_Link_optional = \"\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown - Import a session from another gdrive, the shared gdrive link must point to the specific session's folder that contains the trained CKPT, remove any intermediary CKPT if any.\n",
        "\n",
        "WORKSPACE='/content/gdrive/MyDrive/Fast-Dreambooth'\n",
        "\n",
        "if Session_Link_optional !=\"\":\n",
        "  print('\u001b[1;32mDownloading session...')\n",
        "  with capture.capture_output() as cap:\n",
        "    %cd /content\n",
        "    if not os.path.exists(str(WORKSPACE+'/Sessions')):\n",
        "      %mkdir -p $WORKSPACE'/Sessions'\n",
        "      time.sleep(1)\n",
        "    %cd $WORKSPACE'/Sessions'\n",
        "    !gdown --folder --remaining-ok -O $Session_Name  $Session_Link_optional\n",
        "    %cd $Session_Name\n",
        "    !rm -r instance_images\n",
        "    !unzip instance_images.zip\n",
        "    !rm -r captions\n",
        "    !unzip captions.zip\n",
        "    %cd /content\n",
        "\n",
        "\n",
        "INSTANCE_NAME=Session_Name\n",
        "OUTPUT_DIR=\"/content/models/\"+Session_Name\n",
        "SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
        "INSTANCE_DIR=SESSION_DIR+'/instance_images'\n",
        "CAPTIONS_DIR=SESSION_DIR+'/captions'\n",
        "MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
        "\n",
        "if os.path.exists(str(SESSION_DIR)):\n",
        "  mdls=[ckpt for ckpt in listdir(SESSION_DIR) if ckpt.split(\".\")[-1]==\"ckpt\"]\n",
        "  if not os.path.exists(MDLPTH) and '.ckpt' in str(mdls):\n",
        "\n",
        "    def f(n):\n",
        "      k=0\n",
        "      for i in mdls:\n",
        "        if k==n:\n",
        "          !mv \"$SESSION_DIR/$i\" $MDLPTH\n",
        "        k=k+1\n",
        "\n",
        "    k=0\n",
        "    print('\u001b[1;33mNo final checkpoint model found, select which intermediary checkpoint to use, enter only the number, (000 to skip):\\n\u001b[1;34m')\n",
        "\n",
        "    for i in mdls:\n",
        "      print(str(k)+'- '+i)\n",
        "      k=k+1\n",
        "    n=input()\n",
        "    while int(n)>k-1:\n",
        "      n=input()\n",
        "    if n!=\"000\":\n",
        "      f(int(n))\n",
        "      print('\u001b[1;32mUsing the model '+ mdls[int(n)]+\" ...\")\n",
        "      time.sleep(2)\n",
        "    else:\n",
        "      print('\u001b[1;32mSkipping the intermediary checkpoints.')\n",
        "    del n\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content\n",
        "  resume=False\n",
        "\n",
        "if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n",
        "  print('\u001b[1;32mLoading session with no previous model, using the original model or the custom downloaded model')\n",
        "  if MODEL_NAME==\"\":\n",
        "    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "  else:\n",
        "    print('\u001b[1;32mSession Loaded, proceed to uploading instance images')\n",
        "\n",
        "elif os.path.exists(MDLPTH):\n",
        "  print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "  wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
        "  print('\u001b[1;33mDetecting model version...')\n",
        "  Model_Version=check_output('python det.py --MODEL_PATH '+MDLPTH, shell=True).decode('utf-8').replace('\\n', '')\n",
        "  clear_output()\n",
        "  print('\u001b[1;32m'+Model_Version+' Detected')\n",
        "  !rm det.py\n",
        "  if Model_Version=='1.5':\n",
        "    !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "    print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "    !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $MDLPTH --dump_path \"$OUTPUT_DIR\" --original_config_file config.yaml\n",
        "    !rm /content/config.yaml\n",
        "\n",
        "  elif Model_Version=='V2.1-512px':\n",
        "    !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
        "    print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1-base\n",
        "    !rm /content/convertodiff.py\n",
        "\n",
        "  elif Model_Version=='V2.1-768px':\n",
        "    !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
        "    print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1\n",
        "    !rm /content/convertodiff.py\n",
        "\n",
        "\n",
        "  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "    resume=True\n",
        "    clear_output()\n",
        "    print('\u001b[1;32mSession loaded.')\n",
        "  else:\n",
        "    if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mConversion error, if the error persists, remove the CKPT file from the current session folder')\n",
        "\n",
        "elif not os.path.exists(str(SESSION_DIR)):\n",
        "    %mkdir -p \"$INSTANCE_DIR\"\n",
        "    print('\u001b[1;32mCreating session...')\n",
        "    if MODEL_NAME==\"\":\n",
        "      print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "    else:\n",
        "      print('\u001b[1;32mSession created, proceed to uploading instance images')\n",
        "\n",
        "    #@markdown\n",
        "\n",
        "    #@markdown # The most important step is to rename the instance pictures of each subject to a unique unknown identifier, example :\n",
        "    #@markdown - If you have 10 pictures of yourself, simply select them all and rename only one to the chosen identifier for example : phtmejhn, the files would be : phtmejhn (1).jpg, phtmejhn (2).png ....etc then upload them, do the same for other people or objects with a different identifier, and that's it.\n",
        "    #@markdown - Checkout this example : https://i.imgur.com/d2lD3rz.jpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-r_L79gOcfd",
        "outputId": "ea19af7a-1a91-4f79-92e0-5c9744fb4e8c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=5f704027ca7a49f9140c056cac5a97119db91379095bc3e9612913ec767dd199\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wget\n",
        "from IPython.utils import capture"
      ],
      "metadata": {
        "id": "jeJ3knBGOvhl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "cellView": "form",
        "id": "LC4ukG60fgMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55b7e89-bc3e-4a25-e0e7-2803dfc092f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  |               | 0/0 Uploaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1;32mDone, proceed to the next cell\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "import time\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "import wget\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content\n",
        "  if not os.path.exists(\"/content/smart_crop.py\"):\n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/smart_crop.py')\n",
        "  from smart_crop import *\n",
        "\n",
        "#@markdown #Instance Images\n",
        "#@markdown ----\n",
        "\n",
        "#@markdown\n",
        "#@markdown - Run the cell to upload the instance pictures.\n",
        "#@markdown - You can add `external captions` in txt files by simply giving each txt file the same name as the instance image, for example dikgur (1).jpg and dikgur (1).txt, and upload them here, to use the external captions, check the box \"external_captions\" in the training cell. `All the images must have one same extension` jpg or png or....etc\n",
        "\n",
        "Remove_existing_instance_images= True #@param{type: 'boolean'}\n",
        "#@markdown - Uncheck the box to keep the existing instance images.\n",
        "\n",
        "if Remove_existing_instance_images:\n",
        "  if os.path.exists(str(INSTANCE_DIR)):\n",
        "    !rm -r \"$INSTANCE_DIR\"\n",
        "  if os.path.exists(str(CAPTIONS_DIR)):\n",
        "    !rm -r \"$CAPTIONS_DIR\"\n",
        "\n",
        "if not os.path.exists(str(INSTANCE_DIR)):\n",
        "  %mkdir -p \"$INSTANCE_DIR\"\n",
        "if not os.path.exists(str(CAPTIONS_DIR)):\n",
        "  %mkdir -p \"$CAPTIONS_DIR\"\n",
        "\n",
        "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "\n",
        "IMAGES_FOLDER_OPTIONAL=\"/content/drive/MyDrive/Loras/playful_origins_v4/dataset\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown - If you prefer to specify directly the folder of the pictures instead of uploading, this will add the pictures to the existing (if any) instance images. Leave EMPTY to upload.\n",
        "\n",
        "Smart_Crop_images= True #@param{type: 'boolean'}\n",
        "Crop_size = 512 #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"] {type:\"raw\"}\n",
        "\n",
        "#@markdown - Smart crop the images without manual intervention.\n",
        "\n",
        "while IMAGES_FOLDER_OPTIONAL !=\"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n",
        "  print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path :')\n",
        "  IMAGES_FOLDER_OPTIONAL=input('')\n",
        "\n",
        "if IMAGES_FOLDER_OPTIONAL!=\"\":\n",
        "  if os.path.exists(IMAGES_FOLDER_OPTIONAL+\"/.ipynb_checkpoints\"):\n",
        "    %rm -r \"$IMAGES_FOLDER_OPTIONAL\"\"/.ipynb_checkpoints\"\n",
        "\n",
        "  with capture.capture_output() as cap:\n",
        "    !mv $IMAGES_FOLDER_OPTIONAL/*.txt $CAPTIONS_DIR\n",
        "  if Smart_Crop_images:\n",
        "    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      extension = filename.split(\".\")[-1]\n",
        "      identifier=filename.split(\".\")[0]\n",
        "      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n",
        "      file = Image.open(IMAGES_FOLDER_OPTIONAL+\"/\"+filename)\n",
        "      width, height = file.size\n",
        "      if file.size !=(Crop_size, Crop_size):\n",
        "        image=crop_image(file, Crop_size)\n",
        "        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n",
        "            image[0] = image[0].convert(\"RGB\")\n",
        "            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n",
        "        else:\n",
        "            image[0].save(new_path_with_file, format=extension.upper())\n",
        "      else:\n",
        "        !cp \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n",
        "\n",
        "  else:\n",
        "    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      %cp -r \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n",
        "\n",
        "  print('\\n\u001b[1;32mDone, proceed to the next cell')\n",
        "\n",
        "\n",
        "elif IMAGES_FOLDER_OPTIONAL ==\"\":\n",
        "  up=\"\"\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    if filename.split(\".\")[-1]==\"txt\":\n",
        "      shutil.move(filename, CAPTIONS_DIR)\n",
        "    up=[filename for filename in uploaded.keys() if filename.split(\".\")[-1]!=\"txt\"]\n",
        "  if Smart_Crop_images:\n",
        "    for filename in tqdm(up, bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      shutil.move(filename, INSTANCE_DIR)\n",
        "      extension = filename.split(\".\")[-1]\n",
        "      identifier=filename.split(\".\")[0]\n",
        "      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n",
        "      file = Image.open(new_path_with_file)\n",
        "      width, height = file.size\n",
        "      if file.size !=(Crop_size, Crop_size):\n",
        "        image=crop_image(file, Crop_size)\n",
        "        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n",
        "            image[0] = image[0].convert(\"RGB\")\n",
        "            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n",
        "        else:\n",
        "            image[0].save(new_path_with_file, format=extension.upper())\n",
        "      clear_output()\n",
        "  else:\n",
        "    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      shutil.move(filename, INSTANCE_DIR)\n",
        "      clear_output()\n",
        "  print('\\n\u001b[1;32mDone, proceed to the next cell')\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd \"$INSTANCE_DIR\"\n",
        "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "  %cd \"$CAPTIONS_DIR\"\n",
        "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "\n",
        "  %cd $SESSION_DIR\n",
        "  !rm instance_images.zip captions.zip\n",
        "  !zip -r instance_images instance_images\n",
        "  !zip -r captions captions\n",
        "  %cd /content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"INSTANCE_DIR:\", INSTANCE_DIR)\n",
        "!ls \"$INSTANCE_DIR\" | head -n 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGC_ZyfZW-B3",
        "outputId": "db396ba5-c544-47c7-965b-d88f57f2f19f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INSTANCE_DIR: /content/drive/MyDrive/Loras/playful_origins_v4/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/gdrive/MyDrive/Loras/playful_origins_v4/dataset\" | head -n 10\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usA0NOv1XLZJ",
        "outputId": "3b8f4889-6ed4-4d8d-92df-d52dfc5e9cee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMG_6276.jpg\n",
            "IMG_6276.txt\n",
            "IMG_7935.PNG\n",
            "IMG_7935.txt\n",
            "IMG_7936.PNG\n",
            "IMG_7936.txt\n",
            "IMG_7937.JPG\n",
            "IMG_7937.txt\n",
            "IMG_7940.png\n",
            "IMG_7940.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder = \"/content/drive/MyDrive/Loras/playful_origins_v4/dataset\"\n",
        "files = os.listdir(folder)\n",
        "print(f\"Found {len(files)} files in dataset:\")\n",
        "for f in files[:10]:\n",
        "    print(\"  \", f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjskgk-FPm-H",
        "outputId": "6907a1ad-c6a2-40fd-fba3-1f0ab0ddf792"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 files in dataset:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Baw78R-w4T2j"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "#@markdown #Captions (optional)\n",
        "\n",
        "#@markdown - Open a tool to manually `create` captions or edit existing captions of the instance images, do not use captions when training on a face.\n",
        "\n",
        "paths=\"\"\n",
        "out=\"\"\n",
        "widgets_l=\"\"\n",
        "clear_output()\n",
        "def Caption(path):\n",
        "    if path!=\"Select an instance image to caption\":\n",
        "\n",
        "      name = os.path.splitext(os.path.basename(path))[0]\n",
        "      ext=os.path.splitext(os.path.basename(path))[-1][1:]\n",
        "      if ext==\"jpg\" or \"JPG\":\n",
        "        ext=\"JPEG\"\n",
        "\n",
        "      if os.path.exists(CAPTIONS_DIR+\"/\"+name + '.txt'):\n",
        "        with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'r') as f:\n",
        "            text = f.read()\n",
        "      else:\n",
        "        with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'w') as f:\n",
        "            f.write(\"\")\n",
        "            with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'r') as f:\n",
        "                text = f.read()\n",
        "\n",
        "      img=Image.open(os.path.join(INSTANCE_DIR,path))\n",
        "      img=img.convert(\"RGB\")\n",
        "      img=img.resize((420, 420))\n",
        "      image_bytes = BytesIO()\n",
        "      img.save(image_bytes, format=ext, qualiy=10)\n",
        "      image_bytes.seek(0)\n",
        "      image_data = image_bytes.read()\n",
        "      img= image_data\n",
        "      image = widgets.Image(\n",
        "          value=img,\n",
        "          width=420,\n",
        "          height=420\n",
        "      )\n",
        "      text_area = widgets.Textarea(value=text, description='', disabled=False, layout={'width': '300px', 'height': '120px'})\n",
        "\n",
        "\n",
        "      def update_text(text):\n",
        "          with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'w') as f:\n",
        "              f.write(text)\n",
        "\n",
        "      button = widgets.Button(description='Save', button_style='success')\n",
        "      button.on_click(lambda b: update_text(text_area.value))\n",
        "\n",
        "      return widgets.VBox([widgets.HBox([image, text_area, button])])\n",
        "\n",
        "\n",
        "paths = os.listdir(INSTANCE_DIR)\n",
        "widgets_l = widgets.Select(options=[\"Select an instance image to caption\"]+paths, rows=25)\n",
        "\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def click(change):\n",
        "    with out:\n",
        "        out.clear_output()\n",
        "        display(Caption(change.new))\n",
        "\n",
        "widgets_l.observe(click, names='value')\n",
        "display(widgets.HBox([widgets_l, out]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Set your model output folder manually\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Loras/playful_origins_v4/output\"\n",
        "\n",
        "# make sure it exists\n",
        "import os\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"✅ Output directory set to:\", OUTPUT_DIR)\n",
        "!ls -a \"$OUTPUT_DIR\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMTlFKMtaYyW",
        "outputId": "b4cc30f9-029e-4961-9210-17e35b7313a3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Output directory set to: /content/drive/MyDrive/Loras/playful_origins_v4/output\n",
            ".  ..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content\n"
      ],
      "metadata": {
        "id": "0e6UGYGGeESd",
        "outputId": "cbd62627-cf24-46d3-f74b-e18f7a81e980",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  gdrive  __pycache__  sample_data  smart_crop.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content -type f \\( -name \"*.safetensors\" -o -name \"config.yaml\" \\)"
      ],
      "metadata": {
        "id": "LxlTXHSYj0nL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Stable Diffusion v1.5 model weights\n",
        "!wget -q -O /content/model.safetensors https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned.safetensors\n",
        "\n",
        "# Download the corresponding config file\n",
        "!wget -q -O /content/config.yaml https://huggingface.co/runwayml/stable-diffusion-v1-5/raw/main/v1-inference.yaml\n"
      ],
      "metadata": {
        "id": "KQ5x1Y3CkQGg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/stable-diffusion-v1-5\n",
        "\n",
        "!python /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  --checkpoint_path \"/content/model.safetensors\" \\\n",
        "  --dump_path \"/content/stable-diffusion-v1-5\" \\\n",
        "  --original_config_file \"/content/config.yaml\" \\\n",
        "  --from_safetensors\n"
      ],
      "metadata": {
        "id": "hKYEL0KZkqzH",
        "outputId": "2377208d-ffc8-4788-d9b2-6ce92b502474",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-09 01:25:47.313547: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759973147.343635    3212 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759973147.352839    3212 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759973147.374918    3212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759973147.374969    3212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759973147.374974    3212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759973147.374978    3212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "In this conversion only the non-EMA weights are extracted. If you want to instead extract the EMA weights (usually better for inference), please make sure to add the `--extract_ema` flag.\n",
            "config.json: 4.52kB [00:00, 5.62MB/s]\n",
            "tokenizer_config.json: 100% 905/905 [00:00<00:00, 5.45MB/s]\n",
            "vocab.json: 961kB [00:00, 25.0MB/s]\n",
            "merges.txt: 525kB [00:00, 69.1MB/s]\n",
            "special_tokens_map.json: 100% 389/389 [00:00<00:00, 2.11MB/s]\n",
            "tokenizer.json: 2.22MB [00:00, 116MB/s]\n",
            "config.json: 4.55kB [00:00, 16.6MB/s]\n",
            "pytorch_model.bin: 100% 1.22G/1.22G [00:42<00:00, 28.8MB/s]\n",
            "model.safetensors:   1% 9.65M/1.22G [00:01<01:54, 10.6MB/s]\n",
            "preprocessor_config.json: 100% 342/342 [00:00<00:00, 1.07MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/clip/feature_extraction_clip.py:30: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
            "  warnings.warn(\n",
            "model.safetensors: 100% 1.22G/1.22G [00:39<00:00, 31.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/stable-diffusion-v1-5"
      ],
      "metadata": {
        "id": "vWrw25c_ldQp",
        "outputId": "77535bc5-c44e-496b-ed22-55c603a1cfc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature_extractor  safety_checker  text_encoder  unet\n",
            "model_index.json   scheduler\t   tokenizer\t vae\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmQYfZilzY6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "cellView": "form",
        "id": "1-9QbkfAVYYU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "f8b0a290-57b1-4d4f-bb32-2cd2127cb618"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'runwayml/stable-diffusion-v1-5/text_encoder/pytorch_model.bin'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-972702503.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0mV2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODELT_NAME\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/text_encoder/pytorch_model.bin\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m670901463\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0mV2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/genericpath.py\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runwayml/stable-diffusion-v1-5/text_encoder/pytorch_model.bin'"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #Start DreamBooth\n",
        "#@markdown ---\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from google.colab import runtime\n",
        "from subprocess import getoutput\n",
        "import time\n",
        "import random\n",
        "\n",
        "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "if os.path.exists(CAPTIONS_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $CAPTIONS_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "Resume_Training = False #@param {type:\"boolean\"}\n",
        "\n",
        "resume = False            # ✅ add this line\n",
        "Resume_Training = False   # @param {type:\"boolean\"}\n",
        "\n",
        "if resume and not Resume_Training:\n",
        "    print('\\033[1;31mOverwrite your previously trained model ? answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?')\n",
        "    while True:\n",
        "        ansres = input(\"\")\n",
        "        if ansres == 'no':\n",
        "            Resume_Training = True\n",
        "            break\n",
        "        elif ansres == 'yes':\n",
        "            Resume_Training = False\n",
        "            resume = False\n",
        "            break\n",
        "\n",
        "while not Resume_Training and MODEL_NAME==\"\":\n",
        "  print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "  time.sleep(5)\n",
        "\n",
        "#@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n",
        "\n",
        "MODELT_NAME=MODEL_NAME\n",
        "\n",
        "UNet_Training_Steps=1111 #@param{type: 'number'}\n",
        "UNet_Learning_Rate = 2e-6 #@param [\"2e-5\",\"1e-5\",\"9e-6\",\"8e-6\",\"7e-6\",\"6e-6\",\"5e-6\", \"4e-6\", \"3e-6\", \"2e-6\"] {type:\"raw\"}\n",
        "untlr=UNet_Learning_Rate\n",
        "\n",
        "#@markdown - These default settings are for a dataset of 10 pictures which is enough for training a face, start with 1500 or lower, test the model, if not enough, resume training for 200 steps, keep testing until you get the desired output, `set it to 0 to train only the text_encoder`.\n",
        "\n",
        "Text_Encoder_Training_Steps=350 #@param{type: 'number'}\n",
        "\n",
        "#@markdown - 200-450 steps is enough for a small dataset, keep this number small to avoid overfitting, set to 0 to disable, `set it to 0 before resuming training if it is already trained`.\n",
        "\n",
        "Text_Encoder_Learning_Rate = 1e-6 #@param [\"2e-6\", \"1e-6\",\"8e-7\",\"6e-7\",\"5e-7\",\"4e-7\"] {type:\"raw\"}\n",
        "txlr=Text_Encoder_Learning_Rate\n",
        "\n",
        "#@markdown - Learning rate for the text_encoder, keep it low to avoid overfitting (1e-6 is higher than 4e-7)\n",
        "\n",
        "\n",
        "trnonltxt=\"\"\n",
        "if UNet_Training_Steps==0:\n",
        "   trnonltxt=\"--train_only_text_encoder\"\n",
        "\n",
        "Seed=''\n",
        "\n",
        "ofstnse=\"\"\n",
        "Offset_Noise = False #@param {type:\"boolean\"}\n",
        "#@markdown - Always use it for style training.\n",
        "\n",
        "if Offset_Noise:\n",
        "  ofstnse=\"--offset_noise\"\n",
        "\n",
        "External_Captions = True #@param {type:\"boolean\"}\n",
        "#@markdown - Get the captions from a text file for each instance image.\n",
        "extrnlcptn=\"\"\n",
        "if External_Captions:\n",
        "  extrnlcptn=\"--external_captions\"\n",
        "\n",
        "Resolution = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
        "Res=int(Resolution)\n",
        "\n",
        "#@markdown - Higher resolution = Higher quality, make sure the instance images are cropped to this selected size (or larger).\n",
        "\n",
        "fp16 = True\n",
        "\n",
        "if Seed =='' or Seed=='0':\n",
        "  Seed=random.randint(1, 999999)\n",
        "else:\n",
        "  Seed=int(Seed)\n",
        "\n",
        "if fp16:\n",
        "  prec=\"fp16\"\n",
        "else:\n",
        "  prec=\"no\"\n",
        "\n",
        "precision=prec\n",
        "\n",
        "resuming=\"\"\n",
        "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=OUTPUT_DIR\n",
        "  print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "  resuming=\"Yes\"\n",
        "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m')\n",
        "  MODELT_NAME=MODEL_NAME\n",
        "  while MODEL_NAME==\"\":\n",
        "    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "    time.sleep(5)\n",
        "\n",
        "V2=False\n",
        "# Check if the model exists before checking its size\n",
        "if os.path.exists(os.path.join(MODELT_NAME, \"text_encoder\", \"pytorch_model.bin\")):\n",
        "    if os.path.getsize(os.path.join(MODELT_NAME, \"text_encoder\", \"pytorch_model.bin\")) > 670901463:\n",
        "        V2 = True\n",
        "else:\n",
        "    print(f\"\u001b[1;31mModel not found at {MODELT_NAME}. Please ensure the model is downloaded or the session is loaded correctly.\u001b[0m\")\n",
        "    # You might want to add a sys.exit() or raise an error here to stop execution if the model is crucial\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "GCUNET=\"--gradient_checkpointing\"\n",
        "TexRes=Res\n",
        "if Res<=768:\n",
        "  GCUNET=\"\"\n",
        "\n",
        "if V2:\n",
        "  if Res>704:\n",
        "    GCUNET=\"--gradient_checkpointing\"\n",
        "  if Res>576:\n",
        "    TexRes=576\n",
        "\n",
        "if 'A100' in s :\n",
        "   GCUNET=\"\"\n",
        "   TexRes=Res\n",
        "\n",
        "\n",
        "Enable_text_encoder_training= True\n",
        "\n",
        "if Text_Encoder_Training_Steps==0 :\n",
        "   Enable_text_encoder_training= False\n",
        "else:\n",
        "  stptxt=Text_Encoder_Training_Steps\n",
        "\n",
        "\n",
        "#@markdown ---------------------------\n",
        "Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
        "Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
        "if Save_Checkpoint_Every==None:\n",
        "  Save_Checkpoint_Every=1\n",
        "#@markdown - Minimum 200 steps between each save.\n",
        "stp=0\n",
        "Start_saving_from_the_step=500 #@param{type: 'number'}\n",
        "if Start_saving_from_the_step==None:\n",
        "  Start_saving_from_the_step=0\n",
        "if (Start_saving_from_the_step < 200):\n",
        "  Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "stpsv=Start_saving_from_the_step\n",
        "if Save_Checkpoint_Every_n_Steps:\n",
        "  stp=Save_Checkpoint_Every\n",
        "#@markdown - Start saving intermediary checkpoints from this step.\n",
        "\n",
        "Disconnect_after_training=False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown - Auto-disconnect from google colab after the training to avoid wasting compute units.\n",
        "\n",
        "def dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $trnonltxt \\\n",
        "    $extrnlcptn \\\n",
        "    $ofstnse \\\n",
        "    --image_captions_filename \\\n",
        "    --train_text_encoder \\\n",
        "    --dump_only_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$TexRes \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$txlr \\\n",
        "    --lr_scheduler=\"linear\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "def train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps):\n",
        "    clear_output()\n",
        "    if resuming==\"Yes\":\n",
        "      print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "    print('\u001b[1;33mTraining the UNet...\u001b[0m')\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $extrnlcptn \\\n",
        "    $ofstnse \\\n",
        "    --image_captions_filename \\\n",
        "    --train_only_unet \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --Session_dir=$SESSION_DIR \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GCUNET \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$untlr \\\n",
        "    --lr_scheduler=\"linear\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "\n",
        "if Enable_text_encoder_training :\n",
        "  print('\u001b[1;33mTraining the text encoder...\u001b[0m')\n",
        "  if os.path.exists(OUTPUT_DIR+'/'+'text_encoder_trained'):\n",
        "    %rm -r $OUTPUT_DIR\"/text_encoder_trained\"\n",
        "  dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
        "\n",
        "\n",
        "if UNet_Training_Steps!=0:\n",
        "  train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps=UNet_Training_Steps)\n",
        "\n",
        "if UNet_Training_Steps==0 and Text_Encoder_Training_Steps==0 :\n",
        "  print('\u001b[1;32mNothing to do')\n",
        "else:\n",
        "  if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "    prc=\"--fp16\" if precision==\"fp16\" else \"\"\n",
        "    !python /content/diffusers/scripts/convertosdv2.py $prc $OUTPUT_DIR $SESSION_DIR/$Session_Name\".ckpt\"\n",
        "    clear_output()\n",
        "    if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "      clear_output()\n",
        "      print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\")\n",
        "      if Disconnect_after_training :\n",
        "        time.sleep(20)\n",
        "        runtime.unassign()\n",
        "    else:\n",
        "      print(\"\u001b[1;31mSomething went wrong\")\n",
        "  else:\n",
        "    print(\"\u001b[1;31mSomething went wrong\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iVqNi8IDzA1Z"
      },
      "outputs": [],
      "source": [
        "#@markdown #Free Gdrive Space\n",
        "\n",
        "#@markdown Display the list of sessions from your gdrive and choose which ones to remove.\n",
        "\n",
        "import ipywidgets as widgets\n",
        "\n",
        "Sessions=os.listdir(\"/content/gdrive/MyDrive/Fast-Dreambooth/Sessions\")\n",
        "\n",
        "s = widgets.Select(\n",
        "    options=Sessions,\n",
        "    rows=5,\n",
        "    description='',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "out=widgets.Output()\n",
        "\n",
        "d = widgets.Button(\n",
        "    description='Remove',\n",
        "    disabled=False,\n",
        "    button_style='warning',\n",
        "    tooltip='Removet the selected session',\n",
        "    icon='warning'\n",
        ")\n",
        "\n",
        "def rem(d):\n",
        "    with out:\n",
        "        if s.value is not None:\n",
        "            clear_output()\n",
        "            print(\"\u001b[1;33mTHE SESSION \u001b[1;31m\"+s.value+\" \u001b[1;33mHAS BEEN REMOVED FROM YOUR GDRIVE\")\n",
        "            !rm -r '/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/{s.value}'\n",
        "            s.options=os.listdir(\"/content/gdrive/MyDrive/Fast-Dreambooth/Sessions\")\n",
        "        else:\n",
        "            d.close()\n",
        "            s.close()\n",
        "            clear_output()\n",
        "            print(\"\u001b[1;32mNOTHING TO REMOVE\")\n",
        "\n",
        "d.on_click(rem)\n",
        "if s.value is not None:\n",
        "    display(s,d,out)\n",
        "else:\n",
        "    print(\"\u001b[1;32mNOTHING TO REMOVE\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bbKbx185zqlz",
        "AaLtXBbPleBr"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}