{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GTmycology/dreambooth-colab/blob/main/fast-DreamBooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEsNHTtVlbkV"
      },
      "source": [
        "# **Colab Pro notebook from https://github.com/TheLastBen/fast-stable-diffusion. [ComfyUI Colab](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast_stable_diffusion_ComfyUI.ipynb)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "A4Bae3VP6UsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b37c8182-06f6-4520-b08c-4bbe3816bd20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/gdrive/MyDrive/Loras/playful_origins_v4\"\n",
        "INSTANCE_DIR = f\"{BASE_DIR}/dataset\"\n",
        "CAPTIONS_DIR = f\"{BASE_DIR}/captions\"\n",
        "OUTPUT_DIR = f\"{BASE_DIR}/output\"\n",
        "\n",
        "\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
        "PT = \"a photo of [your-unique-identifier] person\"\n",
        "\n",
        "# Create folders if they don't exist\n",
        "for d in [INSTANCE_DIR, CAPTIONS_DIR, OUTPUT_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "print(\"✅ Path check complete:\")\n",
        "print(\"Instance dir:\", INSTANCE_DIR, \"->\", os.path.exists(INSTANCE_DIR))\n",
        "print(\"Captions dir:\", CAPTIONS_DIR, \"->\", os.path.exists(CAPTIONS_DIR))\n",
        "print(\"Output dir:\", OUTPUT_DIR, \"->\", os.path.exists(OUTPUT_DIR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF9AD2SPKCjU",
        "outputId": "73f60d7b-92b1-46df-8ab3-320bd513fbdc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Path check complete:\n",
            "Instance dir: /content/gdrive/MyDrive/Loras/playful_origins_v4/dataset -> True\n",
            "Captions dir: /content/gdrive/MyDrive/Loras/playful_origins_v4/captions -> True\n",
            "Output dir: /content/gdrive/MyDrive/Loras/playful_origins_v4/output -> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folders if they don’t exist\n",
        "for d in [INSTANCE_DIR, CAPTIONS_DIR, OUTPUT_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "print(\"✅ Path check complete:\")\n",
        "print(\"Instance dir:\", INSTANCE_DIR, \"->\", os.path.exists(INSTANCE_DIR))\n",
        "print(\"Captions dir:\", CAPTIONS_DIR, \"->\", os.path.exists(CAPTIONS_DIR))\n",
        "print(\"Output dir:\", OUTPUT_DIR, \"->\", os.path.exists(OUTPUT_DIR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-6pJ7aAQUzW",
        "outputId": "f2848abf-8d85-4c9e-ac0c-d5a5520d1639"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Path check complete:\n",
            "Instance dir: /content/gdrive/MyDrive/Loras/playful_origins_v4/dataset -> True\n",
            "Captions dir: /content/gdrive/MyDrive/Loras/playful_origins_v4/captions -> True\n",
            "Output dir: /content/gdrive/MyDrive/Loras/playful_origins_v4/output -> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R \"/content/drive/MyDrive/Loras/playful_origins_v4\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eErBzwCoSkjL",
        "outputId": "0e806a2a-3f85-40d0-9cd4-9eae5990723b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Loras/playful_origins_v4:\n",
            "captions  dataset  output\n",
            "\n",
            "/content/drive/MyDrive/Loras/playful_origins_v4/captions:\n",
            "\n",
            "/content/drive/MyDrive/Loras/playful_origins_v4/dataset:\n",
            "\n",
            "/content/drive/MyDrive/Loras/playful_origins_v4/output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder = \"/content/drive/MyDrive/Loras/playful_origins_v4/dataset\"\n",
        "files = os.listdir(folder)\n",
        "print(f\"Found {len(files)} files in dataset:\")\n",
        "for f in files[:10]:\n",
        "    print(\"  \", f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NOQWnmKSPQY",
        "outputId": "bb3dbea3-0911-4542-d311-800289dc3bfe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 files in dataset:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF2T8K6ZWqWk",
        "outputId": "916eb991-993f-4666-9dae-96a2658c6dba"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct  9 00:46:40 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "%cd /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdZL1oa8fWtA",
        "outputId": "ab0cfc01-13df-44ec-b10b-06d6cc9ededa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\" -O /content/model.safetensors\n",
        "!wget -q -O /content/config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "\n",
        "# Convert the safetensors model to diffusers format\n",
        "!mkdir -p /content/stable-diffusion-v1-5\n",
        "!python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  --checkpoint_path /content/model.safetensors \\\n",
        "  --dump_path /content/stable-diffusion-v1-5 \\\n",
        "  --original_config_file /content/config.yaml \\\n",
        "  --from_safetensors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc4Bg_CHfZdB",
        "outputId": "cfa3e26b-58de-497d-dcb9-717645d7e8cd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.27.2 transformers accelerate safetensors --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyjJ--GcflKB",
        "outputId": "3223d42f-c4eb-47c3-e941-bbbc06df20de"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers==0.27.2\n",
            "  Downloading diffusers-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (0.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (0.35.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (2.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (11.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.2) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->diffusers==0.27.2) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading diffusers-0.27.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m136.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diffusers, transformers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.35.1\n",
            "    Uninstalling diffusers-0.35.1:\n",
            "      Successfully uninstalled diffusers-0.35.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.2\n",
            "    Uninstalling transformers-4.56.2:\n",
            "      Successfully uninstalled transformers-4.56.2\n",
            "Successfully installed diffusers-0.27.2 transformers-4.57.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the conversion script manually (TheLastBen version)\n",
        "!wget -q -O /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convert_original_stable_diffusion_to_diffusers.py\n",
        "\n",
        "# Make sure your output folder exists\n",
        "!mkdir -p /content/stable-diffusion-v1-5\n",
        "\n",
        "# Convert the model to diffusers format\n",
        "!python /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  --checkpoint_path /content/model.safetensors \\\n",
        "  --dump_path /content/stable-diffusion-v1-5 \\\n",
        "  --original_config_file /content/config.yaml \\\n",
        "  --from_safetensors\n",
        "\n"
      ],
      "metadata": {
        "id": "9fhhnKXzf_Yz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9oha-RMgwqH",
        "outputId": "741d26ff-9596-4b7c-de32-cba42f63f1f2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4.0G\n",
            "-rw-r--r-- 1 root root 1.9K Oct  9 01:03 config.yaml\n",
            "-rw-r--r-- 1 root root    0 Oct  9 01:06 convert_original_stable_diffusion_to_diffusers.py\n",
            "drwxr-xr-x 3 root root 4.0K Oct  9 00:01 drive\n",
            "drwx------ 5 root root 4.0K Oct  9 00:01 gdrive\n",
            "-rw-r--r-- 1 root root 4.0G Oct  9 01:02 model.safetensors\n",
            "drwxr-xr-x 2 root root 4.0K Oct  9 00:03 __pycache__\n",
            "drwxr-xr-x 1 root root 4.0K Oct  7 13:38 sample_data\n",
            "-rw-r--r-- 1 root root 7.7K Oct  9 00:03 smart_crop.py\n",
            "drwxr-xr-x 3 root root 4.0K Oct  9 00:58 stable-diffusion-custom\n",
            "drwxr-xr-x 2 root root 4.0K Oct  9 01:03 stable-diffusion-v1-5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the working conversion script from Hugging Face diffusers\n",
        "!wget -O /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "\n",
        "# Make sure it’s executable\n",
        "!chmod +x /content/convert_original_stable_diffusion_to_diffusers.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmoBgaHbif4t",
        "outputId": "8831898a-ac3d-496a-8e44-d6cbcde26463"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-09 01:16:00--  https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7020 (6.9K) [text/plain]\n",
            "Saving to: ‘/content/convert_original_stable_diffusion_to_diffusers.py’\n",
            "\n",
            "/content/convert_or 100%[===================>]   6.86K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-09 01:16:00 (41.8 MB/s) - ‘/content/convert_original_stable_diffusion_to_diffusers.py’ saved [7020/7020]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  --checkpoint_path /content/model.safetensors \\\n",
        "  --dump_path /content/stable-diffusion-v1-5 \\\n",
        "  --original_config_file /content/config.yaml \\\n",
        "  --from_safetensors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlS2EpnDilue",
        "outputId": "d92ce843-d1cd-4b5d-c52a-69d88b12fd60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-09 01:16:47.093415: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759972607.118615    1011 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759972607.125979    1011 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759972607.145291    1011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759972607.145334    1011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759972607.145339    1011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759972607.145343    1011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/convert_original_stable_diffusion_to_diffusers.py\", line 160, in <module>\n",
            "    pipe = download_from_original_stable_diffusion_ckpt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/stable_diffusion/convert_from_ckpt.py\", line 1273, in download_from_original_stable_diffusion_ckpt\n",
            "    checkpoint = safe_load(checkpoint_path_or_dict, device=\"cpu\")\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/safetensors/torch.py\", line 381, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: No such file or directory: /content/model.safetensors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vOHKtSni35B",
        "outputId": "75a48472-bfa7-4388-f5f5-3aa6f3dc7b2a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12K\n",
            "-rwxr-xr-x 1 root root 6.9K Oct  9 01:16 convert_original_stable_diffusion_to_diffusers.py\n",
            "drwxr-xr-x 1 root root 4.0K Oct  7 13:38 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/stable-diffusion-v1-5\n",
        "!python /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  --checkpoint_path /content/model.safetensors \\\n",
        "  --dump_path /content/stable-diffusion-v1-5 \\\n",
        "  --original_config_file /content/config.yaml \\\n",
        "  --from_safetensors\n"
      ],
      "metadata": {
        "id": "tBqY6UhXgLHl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaR8j3SBmtdb",
        "outputId": "98f92873-f825-45f0-81e1-13d439b27141"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=87f6f5b4687591bdf6b621b035bc9125ef3425fc00a42bd4bb648e4afc7f8027\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.27.2 transformers==4.37.2 accelerate==0.29.3 safetensors==0.4.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ0UudYe4JnF",
        "outputId": "b7f281fb-7c6c-426f-8981-43ca02bc643d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers==0.27.2\n",
            "  Downloading diffusers-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting transformers==4.37.2\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.29.3\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting safetensors==0.4.3\n",
            "  Downloading safetensors-0.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (0.35.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (2.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.27.2) (11.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (6.0.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.2)\n",
            "  Downloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.29.3) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.29.3) (2.8.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.2) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.4.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->diffusers==0.27.2) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.27.2) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (3.0.3)\n",
            "Downloading diffusers-0.27.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: safetensors, tokenizers, diffusers, transformers, accelerate\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.6.2\n",
            "    Uninstalling safetensors-0.6.2:\n",
            "      Successfully uninstalled safetensors-0.6.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.35.1\n",
            "    Uninstalling diffusers-0.35.1:\n",
            "      Successfully uninstalled diffusers-0.35.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.2\n",
            "    Uninstalling transformers-4.56.2:\n",
            "      Successfully uninstalled transformers-4.56.2\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.10.1\n",
            "    Uninstalling accelerate-1.10.1:\n",
            "      Successfully uninstalled accelerate-1.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.29.3 diffusers-0.27.2 safetensors-0.4.3 tokenizers-0.15.2 transformers-4.37.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzs8iI5u4sTj",
        "outputId": "ffaf206d-ebf7-475a-d703-3030517f6673"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-09 02:53:01--  https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7020 (6.9K) [text/plain]\n",
            "Saving to: ‘/content/convert_original_stable_diffusion_to_diffusers.py’\n",
            "\n",
            "/content/convert_or 100%[===================>]   6.86K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-09 02:53:01 (22.2 MB/s) - ‘/content/convert_original_stable_diffusion_to_diffusers.py’ saved [7020/7020]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/convert_original_stable_diffusion_to_diffusers.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwTNKRjJ4xRQ",
        "outputId": "67d47341-3c0b-4ee5-c3b9-ef02c568160e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rwxr-xr-x 1 root root 6.9K Oct  9 02:53 /content/convert_original_stable_diffusion_to_diffusers.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubB6xzCX5Jz0",
        "outputId": "381e04b0-3ab4-42be-e18f-dafbe332cf68"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 7.2G\n",
            "-rwxr-xr-x 1 root root 6.9K Oct  9 02:53  convert_original_stable_diffusion_to_diffusers.py\n",
            "-rw-r--r-- 1 root root 7.0K Oct  9 02:22 'det (1).py'\n",
            "-rw-r--r-- 1 root root 7.0K Oct  9 01:34  det.py\n",
            "-rw-r--r-- 1 root root 7.2G Oct  9 01:24  model.safetensors\n",
            "drwxr-xr-x 1 root root 4.0K Oct  7 13:38  sample_data\n",
            "drwxr-xr-x 2 root root 4.0K Oct  9 02:54  stable-diffusion-custom\n",
            "drwxr-xr-x 9 root root 4.0K Oct  9 01:28  stable-diffusion-v1-5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "MODEL_PATH = \"/content/model.safetensors\"\n",
        "sftnsr = \"--from_safetensors\"\n",
        "\n",
        "print(\"Custom model version set manually to 1.5 — skipping detection.\")\n",
        "clear_output()\n",
        "\n",
        "# Convert from .safetensors to Diffusers\n",
        "!wget -q -O /content/config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "!python /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  --checkpoint_path \"$MODEL_PATH\" \\\n",
        "  --dump_path /content/stable-diffusion-custom \\\n",
        "  --original_config_file /content/config.yaml \\\n",
        "  $sftnsr\n",
        "!rm /content/config.yaml\n",
        "\n",
        "# Confirm conversion result\n",
        "if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "    clear_output()\n",
        "    print(\"✅ DONE! Model converted successfully.\")\n",
        "else:\n",
        "    print(\"❌ Conversion failed — check paths or file type.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlQEfj_t5-22",
        "outputId": "06f58ae5-29e7-49aa-bfea-77741ae16471"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2025-10-09 03:06:13.760905: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759979173.785594   27511 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759979173.793160   27511 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759979173.811316   27511 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759979173.811364   27511 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759979173.811369   27511 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759979173.811376   27511 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.12/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "In this conversion only the non-EMA weights are extracted. If you want to instead extract the EMA weights (usually better for inference), please make sure to add the `--extract_ema` flag.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/convert_original_stable_diffusion_to_diffusers.py\", line 160, in <module>\n",
            "    pipe = download_from_original_stable_diffusion_ckpt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/stable_diffusion/convert_from_ckpt.py\", line 1687, in download_from_original_stable_diffusion_ckpt\n",
            "    pipe = pipeline_class(\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 237, in __init__\n",
            "    self.register_modules(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py\", line 569, in register_modules\n",
            "    not_compiled_module = _unwrap_model(module)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py\", line 286, in _unwrap_model\n",
            "    from peft import PeftModel\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/__init__.py\", line 17, in <module>\n",
            "    from .auto import (\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/auto.py\", line 31, in <module>\n",
            "    from .config import PeftConfig\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/config.py\", line 24, in <module>\n",
            "    from .utils import CONFIG_NAME, PeftType, TaskType\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/utils/__init__.py\", line 16, in <module>\n",
            "    from .loftq_utils import replace_lora_weights_loftq\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/utils/loftq_utils.py\", line 25, in <module>\n",
            "    from accelerate.utils.memory import clear_device_cache\n",
            "ImportError: cannot import name 'clear_device_cache' from 'accelerate.utils.memory' (/usr/local/lib/python3.12/dist-packages/accelerate/utils/memory.py)\n",
            "❌ Conversion failed — check paths or file type.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate==0.21.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKgsKfZp8Pp0",
        "outputId": "763f630b-9a37-453d-9ded-7fc6e965417b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate==0.21.0\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.21.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.21.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.21.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate==0.21.0) (6.0.3)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.21.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (3.0.3)\n",
            "Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.29.3\n",
            "    Uninstalling accelerate-0.29.3:\n",
            "      Successfully uninstalled accelerate-0.29.3\n",
            "Successfully installed accelerate-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface-hub==0.25.2 diffusers==0.25.0 transformers==4.37.2 accelerate==0.29.3 safetensors==0.4.3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nocijiSY7Q0Z",
        "outputId": "b0457a18-8202-4aea-ebad-1fb53a4548d8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface-hub==0.25.2\n",
            "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting diffusers==0.25.0\n",
            "  Downloading diffusers-0.25.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers==4.37.2 in /usr/local/lib/python3.12/dist-packages (4.37.2)\n",
            "Requirement already satisfied: accelerate==0.29.3 in /usr/local/lib/python3.12/dist-packages (0.29.3)\n",
            "Requirement already satisfied: safetensors==0.4.3 in /usr/local/lib/python3.12/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.25.2) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.25.2) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.25.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.25.2) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.25.2) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.25.2) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.25.2) (4.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.25.0) (8.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers==0.25.0) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.25.0) (2024.11.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.25.0) (11.3.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (0.15.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.29.3) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.29.3) (2.8.0+cu126)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.4.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->diffusers==0.25.0) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.25.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.25.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.25.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.25.2) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (3.0.3)\n",
            "Downloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diffusers-0.25.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub, diffusers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.27.2\n",
            "    Uninstalling diffusers-0.27.2:\n",
            "      Successfully uninstalled diffusers-0.27.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.47.2 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.25.2 which is incompatible.\n",
            "sentence-transformers 5.1.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed diffusers-0.25.0 huggingface-hub-0.25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show diffusers huggingface-hub | grep Version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4CDQ7_v7n6T",
        "outputId": "5f2e3932-bbb1-4842-820e-dc2efff13adf"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version: 0.25.0\n",
            "Version: 0.25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface-hub==0.19.4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFaDt98X6fw1",
        "outputId": "f8f86730-a1a2-46c8-c151-b8a7d7359ea7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface-hub==0.19.4\n",
            "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.19.4) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.19.4) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.19.4) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.19.4) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.19.4) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.19.4) (4.15.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.19.4) (25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.19.4) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.19.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.19.4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.19.4) (2025.8.3)\n",
            "Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.35.3\n",
            "    Uninstalling huggingface-hub-0.35.3:\n",
            "      Successfully uninstalled huggingface-hub-0.35.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "diffusers 0.27.2 requires huggingface-hub>=0.20.2, but you have huggingface-hub 0.19.4 which is incompatible.\n",
            "gradio 5.47.2 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.19.4 which is incompatible.\n",
            "sentence-transformers 5.1.1 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.19.4 which is incompatible.\n",
            "sentence-transformers 5.1.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\n",
            "peft 0.17.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.19.4 which is incompatible.\n",
            "datasets 4.0.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.19.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.19.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/stable-diffusion-custom\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qi0GzLLIWn4",
        "outputId": "90c5a11e-d831-4a5d-d9ed-4a0a87f7a0a2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  --checkpoint_path /content/ComfyUI/models/checkpoints/Playful_OriginsV4.0.ckpt \\\n",
        "  --dump_path /content/stable-diffusion-custom \\\n",
        "  --device cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIJTBSQHJNbq",
        "outputId": "0156eef1-db17-4203-a7fc-ad2594a2d0be"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2025-10-09 04:08:40.553269: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759982920.577492   42501 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759982920.584847   42501 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759982920.602937   42501 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759982920.602985   42501 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759982920.602990   42501 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759982920.602996   42501 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.12/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/convert_original_stable_diffusion_to_diffusers.py\", line 160, in <module>\n",
            "    pipe = download_from_original_stable_diffusion_ckpt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/stable_diffusion/convert_from_ckpt.py\", line 1263, in download_from_original_stable_diffusion_ckpt\n",
            "    checkpoint = torch.load(checkpoint_path_or_dict, map_location=device)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1484, in load\n",
            "    with _open_file_like(f, \"rb\") as opened_file:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 759, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 740, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "                     ^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/ComfyUI/models/checkpoints/Playful_OriginsV4.0.ckpt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3SsbIlxw66N"
      },
      "source": [
        "# Model Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d32591-0e6b-4290-939e-013d50a250cc",
        "id": "tYH6amOweUtV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using Stable Diffusion v1.5 from Hugging Face: runwayml/stable-diffusion-v1-5\n",
            "📦 Custom Hugging Face model path set: runwayml/stable-diffusion-v1-5\n"
          ]
        }
      ],
      "source": [
        "#@title Model Download\n",
        "from IPython.utils import capture\n",
        "import os\n",
        "import time\n",
        "import urllib.request\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Set the model version you want to use\n",
        "Model_Version = \"1.5\"  #@param [\"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
        "\n",
        "# Optional: If you want to load a model from Hugging Face directly\n",
        "Path_to_HuggingFace = \"runwayml/stable-diffusion-v1-5\"  #@param {type:\"string\"}\n",
        "\n",
        "# These will be ignored unless you're using a custom model\n",
        "MODEL_PATH = \"\"  #@param {type:\"string\"}\n",
        "MODEL_LINK = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "# This sets the model destination path based on version\n",
        "if Model_Version == \"1.5\":\n",
        "    MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
        "    print(\"✅ Using Stable Diffusion v1.5 from Hugging Face:\", MODEL_NAME)\n",
        "\n",
        "elif Model_Version == \"V2.1-512px\":\n",
        "    MODEL_NAME = \"stabilityai/stable-diffusion-2-1-base\"\n",
        "    print(\"✅ Using Stable Diffusion v2.1-512px from Hugging Face:\", MODEL_NAME)\n",
        "\n",
        "elif Model_Version == \"V2.1-768px\":\n",
        "    MODEL_NAME = \"stabilityai/stable-diffusion-2-1\"\n",
        "    print(\"✅ Using Stable Diffusion v2.1-768px from Hugging Face:\", MODEL_NAME)\n",
        "\n",
        "# Override MODEL_NAME if a custom HF path is given\n",
        "if Path_to_HuggingFace:\n",
        "    MODEL_NAME = Path_to_HuggingFace\n",
        "    print(\"📦 Custom Hugging Face model path set:\", MODEL_NAME)\n",
        "\n",
        "# At this point, MODEL_NAME is ready to be used by the training or inference cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INSTANCE_DIR = \"/content/gdrive/MyDrive/Loras/playful_origins_v4/dataset\"\n",
        "CAPTIONS_DIR = \"/content/gdrive/MyDrive/Loras/playful_origins_v4/captions\"\n",
        "OUTPUT_DIR   = \"/content/gdrive/MyDrive/Loras/playful_origins_v4/output\"\n",
        "\n",
        "print(\"✅ Paths updated:\")\n",
        "print(\"INSTANCE_DIR:\", INSTANCE_DIR)\n",
        "print(\"CAPTIONS_DIR:\", CAPTIONS_DIR)\n",
        "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF9fxKthYPNs",
        "outputId": "e1337f46-8827-4f6e-95fe-dbeeb2c30cb3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Paths updated:\n",
            "INSTANCE_DIR: /content/gdrive/MyDrive/Loras/playful_origins_v4/dataset\n",
            "CAPTIONS_DIR: /content/gdrive/MyDrive/Loras/playful_origins_v4/captions\n",
            "OUTPUT_DIR: /content/gdrive/MyDrive/Loras/playful_origins_v4/output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"$INSTANCE_DIR\" | head -n 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQOFZvUlYXU2",
        "outputId": "ca13c47d-1225-4343-a32f-34b9c9c8a620"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMG_6276.jpg\n",
            "IMG_6276.txt\n",
            "IMG_7935.PNG\n",
            "IMG_7935.txt\n",
            "IMG_7936.PNG\n",
            "IMG_7936.txt\n",
            "IMG_7937.JPG\n",
            "IMG_7937.txt\n",
            "IMG_7940.png\n",
            "IMG_7940.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tN76Cj5P3RL"
      },
      "source": [
        "# Dreambooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A1B299g-_VJo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from os import listdir\n",
        "from os.path import isfile\n",
        "from subprocess import check_output\n",
        "import wget\n",
        "import time\n",
        "\n",
        "#@markdown #Create/Load a Session\n",
        "\n",
        "try:\n",
        "  MODEL_NAME\n",
        "  pass\n",
        "except:\n",
        "  MODEL_NAME=\"\"\n",
        "\n",
        "PT=\"\"\n",
        "\n",
        "Session_Name = \"\" #@param{type: 'string'}\n",
        "while Session_Name==\"\":\n",
        "  print('\u001b[1;31mInput the Session Name:')\n",
        "  Session_Name=input('')\n",
        "Session_Name=Session_Name.replace(\" \",\"_\")\n",
        "\n",
        "#@markdown - Enter the session name, it if it exists, it will load it, otherwise it'll create an new session.\n",
        "\n",
        "Session_Link_optional = \"\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown - Import a session from another gdrive, the shared gdrive link must point to the specific session's folder that contains the trained CKPT, remove any intermediary CKPT if any.\n",
        "\n",
        "WORKSPACE='/content/gdrive/MyDrive/Fast-Dreambooth'\n",
        "\n",
        "if Session_Link_optional !=\"\":\n",
        "  print('\u001b[1;32mDownloading session...')\n",
        "  with capture.capture_output() as cap:\n",
        "    %cd /content\n",
        "    if not os.path.exists(str(WORKSPACE+'/Sessions')):\n",
        "      %mkdir -p $WORKSPACE'/Sessions'\n",
        "      time.sleep(1)\n",
        "    %cd $WORKSPACE'/Sessions'\n",
        "    !gdown --folder --remaining-ok -O $Session_Name  $Session_Link_optional\n",
        "    %cd $Session_Name\n",
        "    !rm -r instance_images\n",
        "    !unzip instance_images.zip\n",
        "    !rm -r captions\n",
        "    !unzip captions.zip\n",
        "    %cd /content\n",
        "\n",
        "\n",
        "INSTANCE_NAME=Session_Name\n",
        "OUTPUT_DIR=\"/content/models/\"+Session_Name\n",
        "SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
        "INSTANCE_DIR=SESSION_DIR+'/instance_images'\n",
        "CAPTIONS_DIR=SESSION_DIR+'/captions'\n",
        "MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
        "\n",
        "if os.path.exists(str(SESSION_DIR)):\n",
        "  mdls=[ckpt for ckpt in listdir(SESSION_DIR) if ckpt.split(\".\")[-1]==\"ckpt\"]\n",
        "  if not os.path.exists(MDLPTH) and '.ckpt' in str(mdls):\n",
        "\n",
        "    def f(n):\n",
        "      k=0\n",
        "      for i in mdls:\n",
        "        if k==n:\n",
        "          !mv \"$SESSION_DIR/$i\" $MDLPTH\n",
        "        k=k+1\n",
        "\n",
        "    k=0\n",
        "    print('\u001b[1;33mNo final checkpoint model found, select which intermediary checkpoint to use, enter only the number, (000 to skip):\\n\u001b[1;34m')\n",
        "\n",
        "    for i in mdls:\n",
        "      print(str(k)+'- '+i)\n",
        "      k=k+1\n",
        "    n=input()\n",
        "    while int(n)>k-1:\n",
        "      n=input()\n",
        "    if n!=\"000\":\n",
        "      f(int(n))\n",
        "      print('\u001b[1;32mUsing the model '+ mdls[int(n)]+\" ...\")\n",
        "      time.sleep(2)\n",
        "    else:\n",
        "      print('\u001b[1;32mSkipping the intermediary checkpoints.')\n",
        "    del n\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content\n",
        "  resume=False\n",
        "\n",
        "if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n",
        "  print('\u001b[1;32mLoading session with no previous model, using the original model or the custom downloaded model')\n",
        "  if MODEL_NAME==\"\":\n",
        "    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "  else:\n",
        "    print('\u001b[1;32mSession Loaded, proceed to uploading instance images')\n",
        "\n",
        "elif os.path.exists(MDLPTH):\n",
        "  print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "  wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
        "  print('\u001b[1;33mDetecting model version...')\n",
        "  Model_Version=check_output('python det.py --MODEL_PATH '+MDLPTH, shell=True).decode('utf-8').replace('\\n', '')\n",
        "  clear_output()\n",
        "  print('\u001b[1;32m'+Model_Version+' Detected')\n",
        "  !rm det.py\n",
        "  if Model_Version=='1.5':\n",
        "    !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "    print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "    !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $MDLPTH --dump_path \"$OUTPUT_DIR\" --original_config_file config.yaml\n",
        "    !rm /content/config.yaml\n",
        "\n",
        "  elif Model_Version=='V2.1-512px':\n",
        "    !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
        "    print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1-base\n",
        "    !rm /content/convertodiff.py\n",
        "\n",
        "  elif Model_Version=='V2.1-768px':\n",
        "    !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
        "    print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1\n",
        "    !rm /content/convertodiff.py\n",
        "\n",
        "\n",
        "  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "    resume=True\n",
        "    clear_output()\n",
        "    print('\u001b[1;32mSession loaded.')\n",
        "  else:\n",
        "    if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mConversion error, if the error persists, remove the CKPT file from the current session folder')\n",
        "\n",
        "elif not os.path.exists(str(SESSION_DIR)):\n",
        "    %mkdir -p \"$INSTANCE_DIR\"\n",
        "    print('\u001b[1;32mCreating session...')\n",
        "    if MODEL_NAME==\"\":\n",
        "      print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "    else:\n",
        "      print('\u001b[1;32mSession created, proceed to uploading instance images')\n",
        "\n",
        "    #@markdown\n",
        "\n",
        "    #@markdown # The most important step is to rename the instance pictures of each subject to a unique unknown identifier, example :\n",
        "    #@markdown - If you have 10 pictures of yourself, simply select them all and rename only one to the chosen identifier for example : phtmejhn, the files would be : phtmejhn (1).jpg, phtmejhn (2).png ....etc then upload them, do the same for other people or objects with a different identifier, and that's it.\n",
        "    #@markdown - Checkout this example : https://i.imgur.com/d2lD3rz.jpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-r_L79gOcfd",
        "outputId": "ea19af7a-1a91-4f79-92e0-5c9744fb4e8c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=5f704027ca7a49f9140c056cac5a97119db91379095bc3e9612913ec767dd199\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wget\n",
        "from IPython.utils import capture"
      ],
      "metadata": {
        "id": "jeJ3knBGOvhl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "cellView": "form",
        "id": "LC4ukG60fgMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b773d050-153c-4bca-fc80-06335becfeb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  |               | 0/0 Uploaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1;32mDone, proceed to the next cell\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "import time\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "import wget\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content\n",
        "  if not os.path.exists(\"/content/smart_crop.py\"):\n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/smart_crop.py')\n",
        "  from smart_crop import *\n",
        "\n",
        "#@markdown #Instance Images\n",
        "#@markdown ----\n",
        "\n",
        "#@markdown\n",
        "#@markdown - Run the cell to upload the instance pictures.\n",
        "#@markdown - You can add `external captions` in txt files by simply giving each txt file the same name as the instance image, for example dikgur (1).jpg and dikgur (1).txt, and upload them here, to use the external captions, check the box \"external_captions\" in the training cell. `All the images must have one same extension` jpg or png or....etc\n",
        "\n",
        "Remove_existing_instance_images= True #@param{type: 'boolean'}\n",
        "#@markdown - Uncheck the box to keep the existing instance images.\n",
        "\n",
        "if Remove_existing_instance_images:\n",
        "  if os.path.exists(str(INSTANCE_DIR)):\n",
        "    !rm -r \"$INSTANCE_DIR\"\n",
        "  if os.path.exists(str(CAPTIONS_DIR)):\n",
        "    !rm -r \"$CAPTIONS_DIR\"\n",
        "\n",
        "if not os.path.exists(str(INSTANCE_DIR)):\n",
        "  %mkdir -p \"$INSTANCE_DIR\"\n",
        "if not os.path.exists(str(CAPTIONS_DIR)):\n",
        "  %mkdir -p \"$CAPTIONS_DIR\"\n",
        "\n",
        "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "\n",
        "IMAGES_FOLDER_OPTIONAL=\"/content/drive/MyDrive/Loras/playful_origins_v4/dataset\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown - If you prefer to specify directly the folder of the pictures instead of uploading, this will add the pictures to the existing (if any) instance images. Leave EMPTY to upload.\n",
        "\n",
        "Smart_Crop_images= True #@param{type: 'boolean'}\n",
        "Crop_size = 512 #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"] {type:\"raw\"}\n",
        "\n",
        "#@markdown - Smart crop the images without manual intervention.\n",
        "\n",
        "while IMAGES_FOLDER_OPTIONAL !=\"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n",
        "  print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path :')\n",
        "  IMAGES_FOLDER_OPTIONAL=input('')\n",
        "\n",
        "if IMAGES_FOLDER_OPTIONAL!=\"\":\n",
        "  if os.path.exists(IMAGES_FOLDER_OPTIONAL+\"/.ipynb_checkpoints\"):\n",
        "    %rm -r \"$IMAGES_FOLDER_OPTIONAL\"\"/.ipynb_checkpoints\"\n",
        "\n",
        "  with capture.capture_output() as cap:\n",
        "    !mv $IMAGES_FOLDER_OPTIONAL/*.txt $CAPTIONS_DIR\n",
        "  if Smart_Crop_images:\n",
        "    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      extension = filename.split(\".\")[-1]\n",
        "      identifier=filename.split(\".\")[0]\n",
        "      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n",
        "      file = Image.open(IMAGES_FOLDER_OPTIONAL+\"/\"+filename)\n",
        "      width, height = file.size\n",
        "      if file.size !=(Crop_size, Crop_size):\n",
        "        image=crop_image(file, Crop_size)\n",
        "        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n",
        "            image[0] = image[0].convert(\"RGB\")\n",
        "            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n",
        "        else:\n",
        "            image[0].save(new_path_with_file, format=extension.upper())\n",
        "      else:\n",
        "        !cp \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n",
        "\n",
        "  else:\n",
        "    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      %cp -r \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n",
        "\n",
        "  print('\\n\u001b[1;32mDone, proceed to the next cell')\n",
        "\n",
        "\n",
        "elif IMAGES_FOLDER_OPTIONAL ==\"\":\n",
        "  up=\"\"\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    if filename.split(\".\")[-1]==\"txt\":\n",
        "      shutil.move(filename, CAPTIONS_DIR)\n",
        "    up=[filename for filename in uploaded.keys() if filename.split(\".\")[-1]!=\"txt\"]\n",
        "  if Smart_Crop_images:\n",
        "    for filename in tqdm(up, bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      shutil.move(filename, INSTANCE_DIR)\n",
        "      extension = filename.split(\".\")[-1]\n",
        "      identifier=filename.split(\".\")[0]\n",
        "      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n",
        "      file = Image.open(new_path_with_file)\n",
        "      width, height = file.size\n",
        "      if file.size !=(Crop_size, Crop_size):\n",
        "        image=crop_image(file, Crop_size)\n",
        "        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n",
        "            image[0] = image[0].convert(\"RGB\")\n",
        "            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n",
        "        else:\n",
        "            image[0].save(new_path_with_file, format=extension.upper())\n",
        "      clear_output()\n",
        "  else:\n",
        "    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      shutil.move(filename, INSTANCE_DIR)\n",
        "      clear_output()\n",
        "  print('\\n\u001b[1;32mDone, proceed to the next cell')\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd \"$INSTANCE_DIR\"\n",
        "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "  %cd \"$CAPTIONS_DIR\"\n",
        "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "\n",
        "  %cd $SESSION_DIR\n",
        "  !rm instance_images.zip captions.zip\n",
        "  !zip -r instance_images instance_images\n",
        "  !zip -r captions captions\n",
        "  %cd /content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"INSTANCE_DIR:\", INSTANCE_DIR)\n",
        "!ls \"$INSTANCE_DIR\" | head -n 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGC_ZyfZW-B3",
        "outputId": "db396ba5-c544-47c7-965b-d88f57f2f19f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INSTANCE_DIR: /content/drive/MyDrive/Loras/playful_origins_v4/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/gdrive/MyDrive/Loras/playful_origins_v4/dataset\" | head -n 10\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usA0NOv1XLZJ",
        "outputId": "3b8f4889-6ed4-4d8d-92df-d52dfc5e9cee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMG_6276.jpg\n",
            "IMG_6276.txt\n",
            "IMG_7935.PNG\n",
            "IMG_7935.txt\n",
            "IMG_7936.PNG\n",
            "IMG_7936.txt\n",
            "IMG_7937.JPG\n",
            "IMG_7937.txt\n",
            "IMG_7940.png\n",
            "IMG_7940.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder = \"/content/drive/MyDrive/Loras/playful_origins_v4/dataset\"\n",
        "files = os.listdir(folder)\n",
        "print(f\"Found {len(files)} files in dataset:\")\n",
        "for f in files[:10]:\n",
        "    print(\"  \", f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjskgk-FPm-H",
        "outputId": "6907a1ad-c6a2-40fd-fba3-1f0ab0ddf792"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 files in dataset:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Baw78R-w4T2j"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "#@markdown #Captions (optional)\n",
        "\n",
        "#@markdown - Open a tool to manually `create` captions or edit existing captions of the instance images, do not use captions when training on a face.\n",
        "\n",
        "paths=\"\"\n",
        "out=\"\"\n",
        "widgets_l=\"\"\n",
        "clear_output()\n",
        "def Caption(path):\n",
        "    if path!=\"Select an instance image to caption\":\n",
        "\n",
        "      name = os.path.splitext(os.path.basename(path))[0]\n",
        "      ext=os.path.splitext(os.path.basename(path))[-1][1:]\n",
        "      if ext==\"jpg\" or \"JPG\":\n",
        "        ext=\"JPEG\"\n",
        "\n",
        "      if os.path.exists(CAPTIONS_DIR+\"/\"+name + '.txt'):\n",
        "        with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'r') as f:\n",
        "            text = f.read()\n",
        "      else:\n",
        "        with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'w') as f:\n",
        "            f.write(\"\")\n",
        "            with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'r') as f:\n",
        "                text = f.read()\n",
        "\n",
        "      img=Image.open(os.path.join(INSTANCE_DIR,path))\n",
        "      img=img.convert(\"RGB\")\n",
        "      img=img.resize((420, 420))\n",
        "      image_bytes = BytesIO()\n",
        "      img.save(image_bytes, format=ext, qualiy=10)\n",
        "      image_bytes.seek(0)\n",
        "      image_data = image_bytes.read()\n",
        "      img= image_data\n",
        "      image = widgets.Image(\n",
        "          value=img,\n",
        "          width=420,\n",
        "          height=420\n",
        "      )\n",
        "      text_area = widgets.Textarea(value=text, description='', disabled=False, layout={'width': '300px', 'height': '120px'})\n",
        "\n",
        "\n",
        "      def update_text(text):\n",
        "          with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'w') as f:\n",
        "              f.write(text)\n",
        "\n",
        "      button = widgets.Button(description='Save', button_style='success')\n",
        "      button.on_click(lambda b: update_text(text_area.value))\n",
        "\n",
        "      return widgets.VBox([widgets.HBox([image, text_area, button])])\n",
        "\n",
        "\n",
        "paths = os.listdir(INSTANCE_DIR)\n",
        "widgets_l = widgets.Select(options=[\"Select an instance image to caption\"]+paths, rows=25)\n",
        "\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def click(change):\n",
        "    with out:\n",
        "        out.clear_output()\n",
        "        display(Caption(change.new))\n",
        "\n",
        "widgets_l.observe(click, names='value')\n",
        "display(widgets.HBox([widgets_l, out]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Set your model output folder manually\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Loras/playful_origins_v4/output\"\n",
        "\n",
        "# make sure it exists\n",
        "import os\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"✅ Output directory set to:\", OUTPUT_DIR)\n",
        "!ls -a \"$OUTPUT_DIR\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMTlFKMtaYyW",
        "outputId": "b4cc30f9-029e-4961-9210-17e35b7313a3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Output directory set to: /content/drive/MyDrive/Loras/playful_origins_v4/output\n",
            ".  ..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e6UGYGGeESd",
        "outputId": "cbd62627-cf24-46d3-f74b-e18f7a81e980"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  gdrive  __pycache__  sample_data  smart_crop.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content -type f \\( -name \"*.safetensors\" -o -name \"config.yaml\" \\)"
      ],
      "metadata": {
        "id": "LxlTXHSYj0nL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Stable Diffusion v1.5 model weights\n",
        "!wget -q -O /content/model.safetensors https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned.safetensors\n",
        "\n",
        "# Download the corresponding config file\n",
        "!wget -q -O /content/config.yaml https://huggingface.co/runwayml/stable-diffusion-v1-5/raw/main/v1-inference.yaml\n"
      ],
      "metadata": {
        "id": "KQ5x1Y3CkQGg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/stable-diffusion-v1-5\n",
        "\n",
        "!python /content/convert_original_stable_diffusion_to_diffusers.py \\\n",
        "  --checkpoint_path \"/content/model.safetensors\" \\\n",
        "  --dump_path \"/content/stable-diffusion-v1-5\" \\\n",
        "  --original_config_file \"/content/config.yaml\" \\\n",
        "  --from_safetensors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKYEL0KZkqzH",
        "outputId": "2377208d-ffc8-4788-d9b2-6ce92b502474"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-09 01:25:47.313547: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759973147.343635    3212 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759973147.352839    3212 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759973147.374918    3212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759973147.374969    3212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759973147.374974    3212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759973147.374978    3212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "In this conversion only the non-EMA weights are extracted. If you want to instead extract the EMA weights (usually better for inference), please make sure to add the `--extract_ema` flag.\n",
            "config.json: 4.52kB [00:00, 5.62MB/s]\n",
            "tokenizer_config.json: 100% 905/905 [00:00<00:00, 5.45MB/s]\n",
            "vocab.json: 961kB [00:00, 25.0MB/s]\n",
            "merges.txt: 525kB [00:00, 69.1MB/s]\n",
            "special_tokens_map.json: 100% 389/389 [00:00<00:00, 2.11MB/s]\n",
            "tokenizer.json: 2.22MB [00:00, 116MB/s]\n",
            "config.json: 4.55kB [00:00, 16.6MB/s]\n",
            "pytorch_model.bin: 100% 1.22G/1.22G [00:42<00:00, 28.8MB/s]\n",
            "model.safetensors:   1% 9.65M/1.22G [00:01<01:54, 10.6MB/s]\n",
            "preprocessor_config.json: 100% 342/342 [00:00<00:00, 1.07MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/clip/feature_extraction_clip.py:30: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
            "  warnings.warn(\n",
            "model.safetensors: 100% 1.22G/1.22G [00:39<00:00, 31.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/stable-diffusion-v1-5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWrw25c_ldQp",
        "outputId": "77535bc5-c44e-496b-ed22-55c603a1cfc6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature_extractor  safety_checker  text_encoder  unet\n",
            "model_index.json   scheduler\t   tokenizer\t vae\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmQYfZilzY6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1-9QbkfAVYYU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "f8b0a290-57b1-4d4f-bb32-2cd2127cb618"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'runwayml/stable-diffusion-v1-5/text_encoder/pytorch_model.bin'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-972702503.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0mV2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODELT_NAME\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/text_encoder/pytorch_model.bin\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m670901463\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0mV2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/genericpath.py\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runwayml/stable-diffusion-v1-5/text_encoder/pytorch_model.bin'"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown # Start DreamBooth\n",
        "#@markdown ---\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "from google.colab import runtime\n",
        "from subprocess import getoutput\n",
        "\n",
        "# Cleanup .ipynb_checkpoints\n",
        "for path in [INSTANCE_DIR, CAPTIONS_DIR]:\n",
        "    chkpt_path = os.path.join(path, \".ipynb_checkpoints\")\n",
        "    if os.path.exists(chkpt_path):\n",
        "        %rm -r \"$chkpt_path\"\n",
        "\n",
        "# Initialize Resume\n",
        "Resume_Training = False  #@param {type:\"boolean\"}\n",
        "resume = False\n",
        "\n",
        "if resume and not Resume_Training:\n",
        "    print('\\033[1;31mOverwrite previous model? \"yes\" to start new, \"no\" to resume training:')\n",
        "    while True:\n",
        "        ansres = input(\"\").strip().lower()\n",
        "        if ansres == 'no':\n",
        "            Resume_Training = True\n",
        "            break\n",
        "        elif ansres == 'yes':\n",
        "            Resume_Training = False\n",
        "            resume = False\n",
        "            break\n",
        "\n",
        "while not Resume_Training and MODEL_NAME == \"\":\n",
        "    print('\\033[1;31mNo model found. Use the \"Model Download\" cell first.')\n",
        "    time.sleep(5)\n",
        "\n",
        "# Training config\n",
        "UNet_Training_Steps = 1111  #@param {type:'number'}\n",
        "UNet_Learning_Rate = 2e-6  #@param [\"2e-5\", \"1e-5\", \"9e-6\", \"8e-6\", \"7e-6\", \"6e-6\", \"5e-6\", \"4e-6\", \"3e-6\", \"2e-6\"] {type:\"raw\"}\n",
        "Text_Encoder_Training_Steps = 350  #@param {type:'number'}\n",
        "Text_Encoder_Learning_Rate = 1e-6  #@param [\"2e-6\", \"1e-6\", \"8e-7\", \"6e-7\", \"5e-7\", \"4e-7\"] {type:\"raw\"}\n",
        "Offset_Noise = False  #@param {type:\"boolean\"}\n",
        "External_Captions = True  #@param {type:\"boolean\"}\n",
        "Resolution = \"512\"  #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
        "Save_Checkpoint_Every_n_Steps = False  #@param {type:\"boolean\"}\n",
        "Save_Checkpoint_Every = 500  #@param {type:'number'}\n",
        "Start_saving_from_the_step = 500  #@param {type:'number'}\n",
        "Disconnect_after_training = False  #@param {type:\"boolean\"}\n",
        "\n",
        "# Derived flags\n",
        "trnonltxt = \"--train_only_text_encoder\" if UNet_Training_Steps == 0 else \"\"\n",
        "extrnlcptn = \"--external_captions\" if External_Captions else \"\"\n",
        "ofstnse = \"--offset_noise\" if Offset_Noise else \"\"\n",
        "Res = int(Resolution)\n",
        "Seed = random.randint(1, 999999)\n",
        "precision = \"fp16\"\n",
        "\n",
        "# Handle checkpointing\n",
        "if Save_Checkpoint_Every is None:\n",
        "    Save_Checkpoint_Every = 500\n",
        "if Start_saving_from_the_step is None or Start_saving_from_the_step < 200:\n",
        "    Start_saving_from_the_step = Save_Checkpoint_Every\n",
        "stpsv = Start_saving_from_the_step\n",
        "stp = Save_Checkpoint_Every if Save_Checkpoint_Every_n_Steps else 0\n",
        "\n",
        "# Resume handling\n",
        "if Resume_Training and os.path.exists(f\"{OUTPUT_DIR}/unet/diffusion_pytorch_model.bin\"):\n",
        "    MODEL_NAME = OUTPUT_DIR\n",
        "    print(\"\\033[1;32mResuming Training...\\033[0m\")\n",
        "    resuming = \"Yes\"\n",
        "else:\n",
        "    resuming = \"\"\n",
        "\n",
        "# Determine model version\n",
        "V2 = False\n",
        "if os.path.getsize(f\"{MODEL_NAME}/text_encoder/pytorch_model.bin\") > 670_901_463:\n",
        "    V2 = True\n",
        "\n",
        "# Handle memory\n",
        "s = getoutput(\"nvidia-smi\")\n",
        "GCUNET = \"--gradient_checkpointing\" if (Res > 768 or V2 or 'A100' not in s) else \"\"\n",
        "\n",
        "# Define session dir fallback\n",
        "if \"SESSION_DIR\" not in globals():\n",
        "    SESSION_DIR = \"/content/sessions\"\n",
        "if \"Session_Name\" not in globals():\n",
        "    Session_Name = INSTANCE_NAME\n",
        "\n",
        "# Train text encoder\n",
        "def dump_only_textenc():\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $trnonltxt \\\n",
        "    $extrnlcptn \\\n",
        "    $ofstnse \\\n",
        "    --image_captions_filename \\\n",
        "    --train_text_encoder \\\n",
        "    --dump_only_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GCUNET \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$Text_Encoder_Learning_Rate \\\n",
        "    --lr_scheduler=\"linear\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Text_Encoder_Training_Steps\n",
        "\n",
        "# Train UNet\n",
        "def train_only_unet():\n",
        "    clear_output()\n",
        "    if resuming == \"Yes\":\n",
        "        print(\"\\033[1;32mResuming Training...\\033[0m\")\n",
        "    print(\"\\033[1;33mTraining the UNet...\\033[0m\")\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $extrnlcptn \\\n",
        "    $ofstnse \\\n",
        "    --image_captions_filename \\\n",
        "    --train_only_unet \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --Session_dir=$SESSION_DIR \\\n",
        "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GCUNET \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$UNet_Learning_Rate \\\n",
        "    --lr_scheduler=\"linear\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$UNet_Training_Steps\n",
        "\n",
        "# Run training\n",
        "if Text_Encoder_Training_Steps > 0:\n",
        "    print(\"\\033[1;33mTraining the text encoder...\\033[0m\")\n",
        "    if os.path.exists(f\"{OUTPUT_DIR}/text_encoder_trained\"):\n",
        "        %rm -r \"$OUTPUT_DIR/text_encoder_trained\"\n",
        "    dump_only_textenc()\n",
        "\n",
        "if UNet_Training_Steps > 0:\n",
        "    train_only_unet()\n",
        "\n",
        "# Final conversion\n",
        "if UNet_Training_Steps == 0 and Text_Encoder_Training_Steps == 0:\n",
        "    print(\"\\033[1;32mNothing to do\")\n",
        "else:\n",
        "    final_ckpt = f\"/content/models/{INSTANCE_NAME}/unet/diffusion_pytorch_model.bin\"\n",
        "    if os.path.exists(final_ckpt):\n",
        "        prc = \"--fp16\" if precision == \"fp16\" else \"\"\n",
        "        !python /content/diffusers/scripts/convertosdv2.py $prc \"$OUTPUT_DIR\" \"$SESSION_DIR/$Session_Name.ckpt\"\n",
        "        clear_output()\n",
        "        if os.path.exists(f\"{SESSION_DIR}/{INSTANCE_NAME}.ckpt\"):\n",
        "            print(\"\\033[1;32m✅ DONE — Your CKPT is saved to Google Drive in the sessions folder.\")\n",
        "            if Disconnect_after_training:\n",
        "                time.sleep(20)\n",
        "                runtime.unassign()\n",
        "        else:\n",
        "            print(\"\\033[1;31m❌ Something went wrong during conversion.\")\n",
        "    else:\n",
        "        print(\"\\033[1;31m❌ No final model file found to convert.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iVqNi8IDzA1Z"
      },
      "outputs": [],
      "source": [
        "#@markdown #Free Gdrive Space\n",
        "\n",
        "#@markdown Display the list of sessions from your gdrive and choose which ones to remove.\n",
        "\n",
        "import ipywidgets as widgets\n",
        "\n",
        "Sessions=os.listdir(\"/content/gdrive/MyDrive/Fast-Dreambooth/Sessions\")\n",
        "\n",
        "s = widgets.Select(\n",
        "    options=Sessions,\n",
        "    rows=5,\n",
        "    description='',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "out=widgets.Output()\n",
        "\n",
        "d = widgets.Button(\n",
        "    description='Remove',\n",
        "    disabled=False,\n",
        "    button_style='warning',\n",
        "    tooltip='Removet the selected session',\n",
        "    icon='warning'\n",
        ")\n",
        "\n",
        "def rem(d):\n",
        "    with out:\n",
        "        if s.value is not None:\n",
        "            clear_output()\n",
        "            print(\"\u001b[1;33mTHE SESSION \u001b[1;31m\"+s.value+\" \u001b[1;33mHAS BEEN REMOVED FROM YOUR GDRIVE\")\n",
        "            !rm -r '/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/{s.value}'\n",
        "            s.options=os.listdir(\"/content/gdrive/MyDrive/Fast-Dreambooth/Sessions\")\n",
        "        else:\n",
        "            d.close()\n",
        "            s.close()\n",
        "            clear_output()\n",
        "            print(\"\u001b[1;32mNOTHING TO REMOVE\")\n",
        "\n",
        "d.on_click(rem)\n",
        "if s.value is not None:\n",
        "    display(s,d,out)\n",
        "else:\n",
        "    print(\"\u001b[1;32mNOTHING TO REMOVE\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bbKbx185zqlz",
        "AaLtXBbPleBr"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}